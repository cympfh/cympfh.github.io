<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="unidoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>カーネル法 - パターン解析とは何か</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="https://cympfh.cc/resources/css/youtube.css" />
  <link href="https://unpkg.com/prismjs@1.x.0/themes/prism.css" rel="stylesheet" />
  <script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-chtml-full.js"></script>
  <link href="../resources/css/c.css" rel="stylesheet" />
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />

</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-stumbleupon"></i></a>
</header>

<h1 class="title">カーネル法 - パターン解析とは何か</h1>
<p><p class=date style='text-align: right'>2016-09-18 (Sun.)</p> <div class='is-pulled-right'> <a class='tag is-red' href=index.html#機械学習>機械学習</a> </div> % カーネル法によるパターン解析 第2章</p>
<h2>index</h2>
<p><div id=toc></div></p>
<h2>パターン解析とは何か</h2>
<p><strong>パターン解析</strong> はデータからパターンを自動的に獲得することを目指す. これはデータを生成するブラックボックスに関する振る舞いを自動的に学習することである.</p>
<p><strong>パターン</strong> と呼ぶものを具体的に定義する.</p>
<ol>
  <li>
    (データ \(x\) に関する) 一般完全パターン (general exact pattern) とは \(f(x) = 0\) を満たす自明でない関数 \(f\) のこと
    <ul>
      <li>理想環境下での物理法則などがふさわしい</li>
    </ul>
  </li>
  <li>
    一般近似パターン (general approximate pattern) とは \(f(x) \approx 0\) となる非自明な関数 \(f\) のこと
    <ul>
      <li>この \(\approx\) は文字通り approximately equal である</li>
      <li>定義としては曖昧である</li>
    </ul>
  </li>
  <li>
    一般統計パターン (general statistical pattern) とは \(\mathbb{E}_x f(x) \approx 0\)
    <ul>
      <li>ここで \(\mathbb{E}\) は期待値を表す</li>
      <li>\(x\) の事前分布は与えられているものとする</li>
    </ul>
  </li>
</ol>
<h2>パターン解析アルゴリズム</h2>
<p><strong>パターン解析アルゴリズム</strong> とは、有限個のデータから general statistical pattern \(f\) を発見する (或いはそのような \(f\) が無いことを言う) アルゴリズムのこと.</p>
<p>アルゴリズムには次のような性質が求められるだろう:</p>
<ol>
  <li>
    Computational efficiency (計算効率):
    <ul>
      <li>現実世界での計算である以上、大量のデータを高速に捌く必要がある</li>
      <li>データ数に関して多項式時間に抑えられるアルゴリズムを効率的な (efficient) アルゴリズムだという</li>
    </ul>
  </li>
  <li>
    Robustness (頑強性):
    <ul>
      <li>扱うデータが現実世界に関するものであるならば、通常、ノイズが加わっているデータしか観測できない</li>
      <li>ノイズへの強さを頑強性という</li>
      <li>従って発見されるパターンは exact である必要はなく、むしろ approximate な方が求められる</li>
    </ul>
  </li>
  <li>
    Statistical stability (統計的安定性):
    <ul>
      <li>同じ発生源から生成されたデータからは似たパターンが得られるべきである</li>
      <li>
        \(x\) の微小な変化に過敏なパターン \(f\) というのはパターンとしてふさわしくない
        <ul>
          <li>ノイズは無視して</li>
        </ul>
      </li>
      <li>この逆の性質を統計的な安定性という</li>
    </ul>
  </li>
</ol>
<p>統計的安定性についてはいわゆる汎化性能 (the quality of the generalization) と関連が大きい. というかたぶんニュアンスは違うけど同じ現象のことを言っている. 統計的安定性は生成モデルの文脈で言っていて、 汎化性能は予測モデルの予測性能の文脈で言っているだけ. どちらも、似たデータからは似た予測がなされるべき、と言ってるだけ.</p>
<h3>パターン解析と仮説検証</h3>
<p>データの偏りに引き摺られ、成立する確率が小さなパターンを発見してしまうことがありえる. このことを仮説検証の概念でテストする必要がある. 即ち、十分に小さな確率 \(p\) を以って、誤る確率が \(p\)</p>
<h3>過学習 (overfitting)</h3>
<p>データが少く、またそのデータの分布に関する仮定が少なすぎる場合、 そのデータ上でのみ良く成り立ち (misfit) 新しいデータに関してはほぼ成り立たないようなパターンを発見することがあり得る. これを <strong>過学習</strong> という. データが生成される過程に関して何かしらの仮定を入れることは過学習防ぐのに多いに役立つ. よく使われるのは、正規分布を仮定することである. もちろん正規分布に従わないものを正規分布と仮定したところで良いパターンは得られない. この逆の現象を過汎化 (underfit) という.</p>
<h2>教師アリ (supervised) タスク</h2>
<p>データ \(x\) に関してラベル \(y\) が関連づいてるときに \(x\) から \(y\) を予測するようなタスクを考える. このタスクにおける general statistical pattern は次のように記述できる:</p>
\[f(x, y) = \mathcal{L}(y, g(x))\]
<p>関数 \(g\) は予測モデルであり、 \(x\) からラベル \(y\) を予測する. \(\mathcal{L}\) は損失関数と呼ばれ、 \(y\) と \(g(x)\) との近さを非負実数で測る. \(g\) による予測が正しい時に限り \(\mathcal{L}(y, g(x))\) はゼロを示す.</p>
<ol>
  <li>
    \(y\) の取り得る値がちょうど2つの場合を二値分類 (binary classification) という
    <ul>
      <li>\(y \in \{-1,+1\}\) とする</li>
    </ul>
  </li>
  <li>
    有限通りの場合を多クラス分類 (multiclass classification) という
    <ul>
      <li>\(y \in \{1,2,\ldots,N\}\) とする</li>
    </ul>
  </li>
  <li>
    \(y\) の取り合える範囲が \(n\) 次元実数全体の場合を回帰 (regression) という
    <ul>
      <li>\(y \in \mathbb{R}^n\)</li>
    </ul>
  </li>
</ol>
<h2>半教師アリ (semisupervised) タスク</h2>
<p>対応するラベルがついてるデータと、ついていないデータ両方を用いる方法のこと. 大抵、目的は教師アリと同様にラベルの予測. ラベルのついていないデータなら大量に手に入るのでデータの事前分布を推定することで汎化性能を上げることが期待できる.</p>
<h2>教師ナシ (unsupervised) タスク</h2>
<p>データには全てラベルがついていない場合のタスクを教師ナシという. この状況下でのタスクの一つにクラスタリングがある. データ \(x\) のみを比較することで同質なグループに分けるタスクである. 異常検出 (Anomaly, novely-detection) も教師ナシタスクの一つである. これは与えられるデータはほとんど全てが同質であると仮定してそこから大きく外れたデータを検出するタスクである. 例えばある一つの機械の動作を監視し続け、異常を検知する、という適用が考えられる.</p>
<p>他に次元圧縮がある. データが乗る空間 \(X\) のその部分空間 \(V\) に押しやる射影関数 \(P_V: X \rightarrow V (\subseteq X)\) によって</p>
\[f(x) = | P_V(x) - x |^2\]
<p>をパターンとして発見する. PCA (主成分分析; principal components analysis) はこれである. CCS (canonical correlation analysis) はこれと似ているが、データ \(x_1, x_2\) のペアをデータ \(x = (x_1, x_2)\) として、 2つの関係のみを調べる:</p>
\[f(x) = f(x_1, x_2) = | P_V^1(x_1) - P_V^2(x_2) |^2\]

<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>

  <script src="https://cympfh.cc/resources/js/youtube.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>