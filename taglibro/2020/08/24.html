<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="description" content="cympfh.cc/taglibro" />
  <meta property="og:url" content="http://cympfh.cc/taglibro">
  <meta property="og:title" content="Mon Aug 24 2020" />
  <meta property="og:description" content="cympfh.cc/taglibro" />
  <meta property="og:image" content="http://cympfh.cc/resources/img/identicon.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@cympfh" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Mon Aug 24 2020</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../../../resources/css/c.css" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<header class="page-header">
    <a href='../../index.html'><i class="fa fa-save" style="position:absolute; left:0.4em; top:0.4em; width:1.3em;border-radius:0.8em;"></i></a>
</header>
<header>
<h1 class="title">Mon Aug 24 2020</h1>
</header>
<p>あんまり面白くない人間なので、流行りの（まだ流行ってるの！？）ディープラーニングよりもう少し古典的な手法がずっと浮きでいる。 業務でも初めの2年くらいはディープでGPUをぶんぶん回してたけど、今はもうすっかり行列を分解してばかりいる。</p>
<p>推薦システムを行列分解で構築する理論も応用もかなり古くからあるが、研究は今でも脈々と続いている。</p>
<p>分解方法にもバリエーションはあるが基本形は次のようなものだろう。 <span class="math inline">\(n \times m\)</span> 行列 <span class="math inline">\(X\)</span> が与えられる。 このとき次のような <span class="math inline">\(U,V\)</span> を求めよ。 <span class="math display">\[X = UV\]</span> ここで右辺は行列の積である。 そしてその形は <span class="math inline">\(U\)</span> が <span class="math inline">\(n \times k\)</span> で、<span class="math inline">\(V\)</span> は <span class="math inline">\(k \times m\)</span> の形をしている。 ここで <span class="math inline">\(k\)</span> は分解するときに自由に与えることが出来るハイパーパラメータである。 さて厳密に <span class="math inline">\(=\)</span> を満たす <span class="math inline">\(U,V\)</span> を見つけることは理論的には興味深いが、実は推薦システムを構築するときにはそれはむしろ避けたく、「適当な近似的に」イコールであることがむしろ望ましい性質となる。 ここがモデルを考える上で面白いところで、何が適当なのか答えは無いために、研究が今でも続いているわけになる。</p>
<p>なぜ適当さが必要かと言えば、やりたいことは結局 implicit なデータセットからの学習だからである。 つまり、どういうものを想定しているのかと言えば、ネット通販での買い物履歴なんかである。 ユーザー <span class="math inline">\(i\)</span> がアイテム <span class="math inline">\(j\)</span> を買った、というログがある。 例えばこれを <span class="math inline">\(i\)</span> は <span class="math inline">\(j\)</span> に興味がある、と解釈するのは妥当だと思う。 興味がないものにお金を払ったりはしないだろう。 「良いものとして評価した」まで言ってしまうのはどうだろうか。 基本的には良いものと思って買うだろうから、雑に言えば9割方正解だと思う。 でも残りの1割はやっぱり、買ったあとに後悔していることもあるだろう。 今のは買った/買ってないという 0 か 1 かの話をしている。 もっと明示的に、レーティングを与えられることもある。 レビューと言って、例えば5段階評価をユーザーにさせることがある。 これを使えば、買った場合には単に 1 にするのではなくて、1 から 5 の整数で評価することができる。 しかし、それでも同じ問題は尚抱えていて、つまり、膨大に用意されているアイテムの内のほとんどはユーザーはその目にも触れずに何の評価も与えていないのである。 ユーザー <span class="math inline">\(i\)</span> がアイテム <span class="math inline">\(j&#39;\)</span> を買っていない（目にもしていない）という状態を今は仮に <span class="math inline">\(P_i^{j&#39;}=0\)</span> とすることにするが、これは決して、悪い評価を下しているのではなくて、何も評価を下していない。</p>
<p>話を簡単にするために、0 か 1 かの問題設定に戻す。 <span class="math inline">\(P_i^j=1\)</span> は <span class="math inline">\(i\)</span> が <span class="math inline">\(j\)</span> を（高い確率で）良いと評価し、<span class="math inline">\(P_i^j=0\)</span> はただ単に何も評価していないことを表す。</p>
<p>推薦システムの目的はまだ評価していないアイテムの中で気に入りそうなアイテムを見つけることだ。 ユーザー <span class="math inline">\(i\)</span> に対して、 ポジティブデータ <span class="math inline">\(D_i^+ = \{ j \mid P_i^j=1 \}\)</span> と、未観測データ <span class="math inline">\(D_i^! = \{ j \mid P_i^j=0 \}\)</span> から何かしらのモデルを獲得して、<span class="math inline">\(D_i^!\)</span> からポジティブらしいアイテムを推論することと言える。</p>
<p>未観測は未観測です、じゃあ、何もできない。 そこで普通は、</p>
<ol type="1">
<li><span class="math inline">\(D_i^+\)</span> の内のほとんどは実際にポジティブ
<ul>
<li><span class="math inline">\(P_i^j=1\)</span> という値をスコア <span class="math inline">\(1\)</span> だと思う</li>
</ul></li>
<li><span class="math inline">\(D_i^!\)</span> の内のほとんどは実際にネガティブ
<ul>
<li><span class="math inline">\(P_i^j=0\)</span> という値をスコア <span class="math inline">\(0\)</span> だと思う</li>
</ul></li>
</ol>
<p>ということにする。</p>
<p>行列分解 <span class="math inline">\(P=UV\)</span> は、いわば一つのモデル化であり、分解を計算することがモデルの学習だと言えるのだが、 <span class="math inline">\(k\)</span> を適当に小さくしておくのがポイントである。 大きすぎれば例えば <span class="math inline">\(P=P I\)</span> (<span class="math inline">\(I\)</span> は単位行列) といった厳密にイコールになる学習をしてしまうだろう。 しかしこれはただ、ポジティブデータ全てをポジティブに、未観測データ全てをネガティブとして学習しただけである。 <span class="math inline">\(k\)</span> を適当に小さくして、情報を圧縮することで、似たアイテムには似た推論結果を出すようになる。 モデルの表現力をわざと抑えて、汎化性能を担保する作戦である。</p>
<p>ところで学習方法に踏み込んだ話を一つもしていなかった。 行列分解というモデルは、その学習方法すらもモデルの中身になると思う。</p>
<p>何も考えなければ、<span class="math inline">\(X_i^j\)</span> が <span class="math inline">\(1\)</span> の成分は <span class="math inline">\(1\)</span> に、<span class="math inline">\(0\)</span> の成分は <span class="math inline">\(0\)</span> に近づくような <span class="math inline">\(U\)</span> と <span class="math inline">\(V\)</span> を探すだろう。 さっきも言ったように、<span class="math inline">\(0\)</span> というのは単に未観測なだけを表していて、<span class="math inline">\(0\)</span> というスコアを表しているわけではない。 <span class="math inline">\(0\)</span> という値そのものをロスに使わないことで柔軟な学習ができる。 そこで pair-wise な学習が出てくる。 <a href="https://cympfh.cc/paper/index.html#%E9%A1%9E%E4%BC%BC%E5%BA%A6%E5%AD%A6%E7%BF%92">類似度学習</a> とかで散々出てくるやつだ。 すなわち、「ユーザー vs アイテム（一つ）」からスコアを算出しようとするから、<span class="math inline">\(0\)</span> とか <span class="math inline">\(1\)</span> という値が必要なのであって、そうでなくて、「ユーザーに対して、アイテム 1 vs アイテム 2」というアイテムのペアを与えてこれを比較するような学習をさせる。 <span class="math inline">\(D_i^+\)</span> からアイテム <span class="math inline">\(i^+\)</span>、<span class="math inline">\(D_i^!\)</span> からアイテム <span class="math inline">\(i^-\)</span> を持ってくる。 それぞれは高い確率でポジティブデータとネガティブデータである。 このときにそれぞれにスコア <span class="math inline">\(s^+, s^-\)</span> を算出して <span class="math inline">\(s^+ &gt; s^-\)</span> であるようにする。 スコアは結局、「ユーザー vs アイテム」として算出するのだが、直接学習するのはスコアの値じゃなくてあくまで大小比較 <span class="math inline">\(&gt;\)</span> のところ。 というようにするのがこないだ読んだ <a href="https://cympfh.cc/paper/BPR">BPR</a>.</p>
<p>正直、やってることは単純だし、これが2012年になってようやく出たのか、と思う。 全然進んでないなこの分野は。</p>
<p>たぶんまだ誰もやってない研究:</p>
<ul>
<li>情報幾何 vs 行列分解</li>
<li>情報幾何 vs 圏論</li>
</ul>
<footer>
    <p class="is-pulled-right">
    @cympfh / cympfh@gmail.com
    </p>
</footer>
<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>
</body>
</html>
