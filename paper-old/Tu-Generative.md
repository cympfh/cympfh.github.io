% Learning Generative Models via Discriminative Approaches (Tu's generative model)
% http://pages.ucsd.edu/~ztu/publication/cvpr07_gdl.pdf
% 生成モデル

## 概要

(主に画像の) 生成モデルを作りたい.
分類モデルを同時に学ぶことで強い生成モデルを作る.

## 手法

教師あり学習
$(X=\mathbb R^n) \to (Y=\{-1,+1\})$
を考える.
目標は生成モデル $p(x|y=+1)$ の獲得である.
しかし同時に分類モデル $p(y|x)$ の学習も行うことは次のような理由で意味がある.

普通のベイズの定理に従って:
$$p(y=+1|x)=\frac{p(x|y=+1)p(y=+1)}{p(x)} \\
p(y=-1|x)=\frac{p(x|y=-1)p(y=-1)}{p(x)}$$
この2つから
$$p(x|y=+1)=
\frac{
p(y=+1|x) p(y=-1)
}{
p(y=-1|x) p(y=+1)
}
p(x|y=-1)$$
を得る.

事前知識として $p(y=+1), p(y=-1)$ の比を見積もっておく.
簡単に $1:1$ だと都合よく仮定すると、
$$p(x|y=+1) = \frac{p(y=+1|x)}{p(y=-1|x)} p(x|y=-1)$$
になる.

この $p(x|y=-1)$ を $p^r(x)$ と書いて **参照分布 (reference distribution)** と呼ぶ.
また参照分布からサンプリングして得たデータを **疑似負例 (pseudo-negatives)** と呼ぶ.
$$p(x|y=+1) = \frac{p(y=+1|x)}{p(y=-1|x)} p^r(x)$$

さて広大な空間の $X$ からサンプリングして学習するわけにはいかない.
限られたデータだけを選択していく必要がある.

時刻 $t (=1,2,\ldots)$ の時点で学習された参照分布を $p^r_t$ と書くことにする.
同様に、分類器 $p(y|x)$ の時刻 $t$ 時点でのモデルを $q_t$ とする.

初期の参照分布 $p^r_1$ は適当に設定するが、論文では、正例集合 $D$ に対して、
$$p^r_1(x) = \beta \frac{1}{|D|} \sum_{x' \in D} \delta(x-x') + (1-\beta) U(x)$$
などとしている.
ここで $\delta$ は indicator 関数 ($\delta(0)=1, \delta(x)=0 \iff x \ne 0$)、$U(x)$ は一様分布.
特に $D$ のようなものが無いときは $\beta=0$ としたとある.

さてここから $p^r$ を正例の分布に近づけるように学習にする.
それには上の式を更新式として用いればよい.
$$p^r_{t+1}(x) = \frac{1}{Z} \frac{q_1(y=+1|x)}{q_1(y=-1|x)} p^r_t(x)$$
ここで $Z$ は、左辺が確率分布になるようになるための正規化項 ($\int p^r_{t+1}(x) dx=1$).

厳密に $Z$ を計算するには右辺を積分することになるが、
実装上は、モンテカルロ法で見積もったと論文にはある.
たまたま見つけた[野良実装](https://gist.github.com/betatim/5fae2137d83c9964bbedd8d8fd646111) ではそもそも分布を、点集合として持っている.

また $q_{t+1}$ は $p^r_t(x)$ からの疑似負例を参照して $q_t$ から更に強くしてく.

<div class=thm>
### 定理
$$KL\left( p(x|y=+1) \| p^r_{t+1}(x) \right)
\leq
KL\left( p(x|y=+1) \| p^r_t(x) \right)$$

証明は論文にあるので省略.
</div>

これがあるので、更新を繰り返して行けば $p^r_t$ は真の生成モデル $p(x|y=+1)$ に近づく.
