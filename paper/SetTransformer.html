<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="unidoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Set Transformer</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="https://cympfh.cc/resources/css/youtube.css" />
  <link href="https://unpkg.com/prismjs@1.x.0/themes/prism.css" rel="stylesheet" />
  <script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-chtml-full.js"></script>
  <link href="resources/css/c.css" rel="stylesheet" />
  <link href="../resources/css/c.css" rel="stylesheet" />
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />

</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o"></i></a>
</header>

<h1 class="title">Set Transformer</h1>
<p><ul> <li>original paper: <a href=https://arxiv.org/abs/1810.00825>https://arxiv.org/abs/1810.00825</a></li> </ul> <div class='is-pulled-right'> <a class='tag is-blue' href=index.html#深層学習>深層学習</a> <a class='tag is-blue' href=index.html#集合学習>集合学習</a> </div></p>
\[
\def\pool{\mathrm{pool}}
\def\net{\mathrm{net}}
\def\Att{\mathrm{Att}}
\def\Multihead{\mathrm{Multihead}}
\def\MAB{\mathop{\mathrm{MAB}}}
\def\SAB{\mathrm{SAB}}
\def\ISAB{\mathrm{ISAB}}
\def\Norm{\mathrm{Norm}}
\def\rFF{\mathrm{rFF}}
\def\PMA{\mathrm{PMA}}
\]
<h2>概要</h2>
<p>入力が集合であるようなニューラルネットを構成したい. このための方法として set pooling があったが, これに attention つけたら最高になった.</p>
<h2>集合の学習</h2>
<p>事例に対してラベルを学習するような機械を考える. インスタンスの集合 \(\mathcal X\) とラベルの集合 \(\mathcal Y\) について通常は</p>
\[\mathcal X \to \mathcal Y\]
<p>を扱うが, 場合によっては入力が事例の集合であることがある. つまり</p>
\[\mathcal P \mathcal X \to \mathcal Y\]
<p>を考える ( \(\mathcal P \mathcal X\) は \(\mathcal X\) のべき集合).</p>
<p>入力が事例の列なんかの場合, 台集合を取ればこれが適用できる.</p>
<p>集合であるということは次が成り立たなければならない.</p>
<ol>
  <li>
    順序不変性 (permutation invariant)
    <ul>
      <li>\(\{a,b\}\) と \(\{b,a\}\) は同じものである</li>
    </ul>
  </li>
  <li>
    サイズ可変性
    <ul>
      <li>入力は一般に \(X \in \mathcal P \mathcal X\) (i.e. \(X \subset \mathcal X\) ) であることを要請する</li>
      <li>\(X\) の大きさはどんなであっても良いようにしてほしい</li>
    </ul>
  </li>
</ol>
<p>NNs で機械を構成する場合, ややもすれば入力のサイズは固定になり, また RNN などを使えば順序が考慮されてしまう.</p>
<h2>背景</h2>
<h3>Set Pooling</h3>
<p>[Zaheer et al., 2017] による方式では集合に対する pooling を行って</p>
\[\{x_1,\ldots,x_n\} \mapsto \rho(\pool \{ \phi(x_1),\ldots, \phi(x_n) \})\]
<p>とする方法. ここで \(\phi\) は embeggin とか Encoder と呼ばれるもの. また \(\pool\) は例えば max や average などなど集合から特徴量を取り出すような操作. これは順序不変性やサイズ可変性を満たしている. \(\rho \circ \pool\) の部分を合わせて Decoder と呼ぶ.</p>
<p>この論文の手法もこの方式でやる.</p>
<h3>Attention</h3>
<p>\(n\) 個のクエリがあって各クエリは \(d_q\) 次元ベクトルで表現されてるとき, クエリは \(Q \in \mathbb R^{n \times d_q}\) で表現される. キーバリュー \((K, V) \in (\mathbb R^{n_v \times d_q}, \mathbb R^{n_v \times d_v})\) なるものを用いて, このとき attention function (注視関数?) \(\Att\) とは次のようなもの:</p>
\[\Att(Q,K,V;\omega) = \omega(QK^T) V\]
<p>\(\omega : \mathbb R \to \mathbb R\) は活性化関数でここでは要素ごとに適用することで \(\mathbb R^{n \times n_v} \to \mathbb R^{n \times n_v}\) として使ってる.</p>
<h4>Multi-head attention</h4>
<p>[Vaswani et al., 2017] による拡張. \(h\) 個に増やして結果を結合して使う. そのために \(Q,K,V\) に右からそれぞれ \(W_j\) を掛けて違う行列にして, また活性化関数 \(\omega_j\) も \(h\) 個用意する.</p>
\[\Multihead(Q,K,V; \lambda, \omega) = concat(O_1, \ldots, O_h) W^O\]
<p>ただし</p>
<ul>
  <li>\(\lambda = \{W_j^Q, W_j^K, W_j^V\}_{j=1}^h\)</li>
  <li>\(O_j = \Att(QW_j^Q, KW_j^K, VW_j^V; \omega_j)\) ( \(j=1,2,\ldots,h\) )</li>
</ul>
<p>\(\lambda\) も学習可能なパラメータであることに注意. また彼らは \(\omega\) として scaled softmax を用いたそう.</p>
<p>型を書いておくと</p>
\[\Multihead \colon \mathbb R^{n \times d_q} \times \mathbb R^{n_v \times d_q} \times \mathbb R^{n_v \times d_v} \to \mathbb R^{n \times d_v}\]
<h2>Set Transformer</h2>
<p>Attention ベースで集合を処理する機械 Set Transformer を構成する. これは Encoder と Decoder の二つの合成として表現される. まずは必要な部品を定義したあと, Encoder と Decoder をそれぞれ定義する.</p>
<h3>Multihead Attention Block (MAB)</h3>
<p>次を定義する:</p>
\[\MAB \colon \mathbb R^{n \times d} \times \mathbb R^{m \times d} \to \mathbb R^{n \times d}\]
\[\begin{align*}
\MAB(X, Y; \lambda) &amp; = \Norm(H + \rFF(H)) \\
\text{ where } H &amp; = \Norm(X + \Multihead(X, Y, Y; \lambda, \omega)
\end{align*}\]
<p>\(X, Y\) の行は一つの \(d\) 次元ベクトルであって, それが行数分だけある集合を表している. ここで \(\Norm\) は layer normalization で \(\rFF\) は行ごとの feed forward.</p>
<p>("Attention is All You Need" の Position-wise Feed-Forward Network を参考にすると \(\rFF\) は relu を入れるだけの二層NNで \((\max(0, W_1x+b_1)W_2+b_2\) というもの)</p>
<h3>Set Attention Block (SAB)</h3>
<p>\(X=Y\) としたときの MAB を SAB と定める.</p>
\[\SAB \colon \mathbb R^{n \times d} \to \mathbb R^{n \times d}\]
\[\SAB(X; \lambda) = \MAB(X, X; \lambda)\]
<h3>Induced Set Attention Block (ISAB)</h3>
<p>SAB の計算には計算コストがかかり過ぎる. どこの部分のことか言っていないが, 行列の掛け算の話だと思う. つまり \(\mathbb R^{a \times b}\) と \(\mathbb R^{b \times c}\) の掛け算には \(O(abc)\) の計算量が係る. \(X \in \mathbb R^{n \times d}\) について \(\SAB(X)\) を計算するには \(O(n^2d)\) が係る. 論文に書いてあるのは \(d\) を定数として無視して単に \(O(n^2)\) だと言っている.</p>
<p>この計算量を削減したバージョンを作る.</p>
\[\ISAB \colon \mathbb R^{n \times d} \to \mathbb R^{n \times d}\]
\[\begin{align*}
\ISAB_m(X; \lambda) &amp; = \MAB(X, H) \\
\text{ where } H &amp; = \MAB(I_m, X)
\end{align*}\]
<p>ここで \(I_m\) は \(\mathbb R^{m \times d}\) であって彼らはこれを inducing point と呼んでいる. \(H\) は \(\mathbb R^{m \times d}\) であるので全体の計算コストは \(O(mnd)\) になる. つまり \(m\) を適当に小さくすることで計算量を抑えられる.</p>
<p>注意. \(I\) 自体も訓練可能なパラメータである.</p>
<h4>性質</h4>
<p>\(S_n\) 上の任意の置換 \(\pi\) について \(f(\pi x) = \pi(fx)\) となる \(f\) を順序を保つと呼ぶことにする.</p>
<p>\(\SAB\) と \(\ISAB\) は順序を保つ.</p>
<h3>Encoder</h3>
<p>SAB または ISAB を複数縦に重ねたものを Encoder とする. 例えば2つ重ねて</p>
\[\SAB(\SAB(X))\]
\[\ISAB(\ISAB(X))\]
<p>これを Encoder とする. Encoder は一つの行列を受け取って, それと同じ大きさの行列を返す.</p>
<h3>Decoder</h3>
<p>Encoder によって得た \(Z \in \mathbb R^{n \times d}\) を受け取って行に関して集約する操作を行う. 集約の操作は Set Pooling を用いる. つまり行に関して平均を取ったり max を取るなどをして \(k\) 種の特徴量をとるとする. これによって \(Z\) から \(S \in \mathbb R^{k \times d}\) が得られる.</p>
\[\begin{align*}
Decoder(Z; \lambda) &amp; = \rFF(\SAB(\PMA_k(Z))) \\
\text{ where } \PMA_k(Z) &amp; = \MAB(S, \rFF(Z)) \\
S &amp; \leftarrow \text{ set-pooling } Z
\end{align*}\]
<p>ただし彼らが言うには多くの場合, \(k=1\) で十分であり, また \(\SAB\) も省いてしまって十分であったらしい. simple pooling として 平均を取ることをした.</p>
<h4>Prop 1</h4>
<p>Set Transformer は順序不変性を持つ.</p>
<h4>Prop 2</h4>
<p>Set Transformer は順序不変性を持つ関数の万能近似である.</p>
<h3>実験</h3>
<p>データの集合を与えて何かを解くようなタスクを行った.</p>
<ol>
  <li>
    max value regression
    <ul>
      <li>
        実数の集合を与えて \(\max\) を学習させる
        <ul>
          <li>損失は MAE</li>
        </ul>
      </li>
      <li>
        当たり前だけど pooling に max を使うのが最強だった
        <ul>
          <li><code>rFF+pooling(max)</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    counting unique characters
    <ul>
      <li>Omniglot データベースを用いる</li>
      <li>手書き文字画像から20種類の文字を選ぶ</li>
      <li>ウニークなものが何種類か数えるタスク</li>
      <li>なんでも解けるけど Set Transformer が良かった</li>
    </ul>
  </li>
  <li>
    混合分布の最尤推定
    <ul>
      <li>
        点の集合からそれを最尤する \(k\) 個のガウス分布のパラメータを推定させる
        <ul>
          <li>予測は \(k\) 個の \((\mu, \sigma)\)</li>
        </ul>
      </li>
      <li>普通にはEMアルゴリズムで解く問題である</li>
      <li>
        これで画像分類をさせる (meta-clustering)
        <ul>
          <li>Synthetic 2D: 二次元データであって \(k=4\) つのガウス分布に分けさせる</li>
          <li>CIFAR-100: VGG で一つの画像を 512 次元ベクトルに落としておく. 4つのクラスだけ選んで使う. \(k=4\)</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>

  <script src="https://cympfh.cc/resources/js/youtube.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>