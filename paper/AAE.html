<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Adversarial Autoencoders (AAEs)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../resources/css/c.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header class="page-header">
    <a href='index.html'><img src="../resources/img/identicon.png" style="position:relative; top:0.4em; width:1.3em;border-radius:0.8em;" /> paper/</a>
</header>
<header>
<h1 class="title">Adversarial Autoencoders (AAEs)</h1>
</header>
<ul>
<li>
original paper: <a href=https://arxiv.org/abs/1511.05644>https://arxiv.org/abs/1511.05644</a>
</li>
</ul>
<div class="is-pulled-right">
<p><a class='tag is-blue' href=index.html#深層学習>深層学習</a> <a class='tag is-blue' href=index.html#オートエンコーダ>オートエンコーダ</a> <a class='tag is-blue' href=index.html#クラスタリング>クラスタリング</a></p>
</div>
<h2 id="概要">概要</h2>
<p>GAN を用いた確率的自己符号化器</p>
<h2 id="gan-復習事項">GAN (復習事項)</h2>
<ul>
<li>ある本物事例 <span class="math inline">\(\{ x_i \}_i\)</span> がある</li>
<li>2つの機械 <span class="math inline">\(G\)</span> 及び <span class="math inline">\(D\)</span> を NNs で構成する</li>
<li>適当な確率分布 <span class="math inline">\(Pr(z)\)</span> からランダムなノイズ <span class="math inline">\(z\)</span> をサンプリング</li>
<li><span class="math inline">\(G\)</span> はそのような <span class="math inline">\(z\)</span> から本物そっくりの偽物事例 <span class="math inline">\(x&#39;\)</span> を出力する
<ul>
<li><span class="math inline">\(x&#39; = G(z)\)</span></li>
</ul></li>
<li><span class="math inline">\(D\)</span> は入力 <span class="math inline">\(x\)</span> が本物 (現実の事例) か偽物 (<span class="math inline">\(G\)</span> によって生成されたもの) かを識別する
<ul>
<li>本物だとする確率を <span class="math inline">\(D(x)\)</span> とする</li>
</ul></li>
</ul>
<p>目的関数は</p>
<p><span class="math display">\[\min_G \max_D
\left[
\mathbb{E}_{x \sim \text{real}} \log D(x)
+ \mathbb{E}_{z \sim Pr(z)} (1 - \log D(G(z)))
\right]\]</span></p>
<h2 id="aae">AAE</h2>
<p>GAN と同様に <span class="math inline">\(G\)</span> 及び <span class="math inline">\(D\)</span> を構成する</p>
<ul>
<li>適当な分布 <span class="math inline">\(Pr(z)\)</span> からサンプリングした <span class="math inline">\(z\)</span> が <strong>本物</strong> 事例</li>
<li><span class="math inline">\(G\)</span> は入力 <span class="math inline">\(x\)</span> から <strong>偽物</strong> 事例 <span class="math inline">\(z\)</span> を出力する
<ul>
<li>オートエンコーダーにおける符号化</li>
</ul></li>
<li><span class="math inline">\(D\)</span> は入力 <span class="math inline">\(z\)</span> が <span class="math inline">\(Pr(z)\)</span> 由来であるか、 <span class="math inline">\(G\)</span> 由来であるかを識別する
<ul>
<li>回帰で解くより 2-class 分類として解く (最後softmaxする) 方が良い</li>
<li>前者である確率を <span class="math inline">\(D(z)\)</span> とする</li>
</ul></li>
</ul>
<figure>
<img src="img/aae/aae.png" />
</figure>
<p>先ほどの GAN の説明と、<span class="math inline">\(x\)</span> と <span class="math inline">\(z\)</span> とが入れ替わってることに註意. 従って目的関数は次のようになる.</p>
<p><span class="math display">\[\min_G \max_D
\left[
\mathbb{E}_{z \sim Pr(z)} \log D(z)
+ \mathbb{E}_{x \sim \text{examples}} (1 - \log D(G(x)))
\right]\]</span></p>
<p>以上で学習した <span class="math display">\[G: x \mapsto z\]</span></p>
<p>を自己符号化器として AAE と呼ぶ.</p>
<h2 id="応用例">応用例</h2>
<h3 id="supervised-aae">Supervised AAE</h3>
<p>Autoencoders は教師ナシ学習の一種だが、 データ <span class="math inline">\(x\)</span> にラベルが着いてるのならばそれも有効に使いたい.</p>
<p>論文では MNIST と SVHN を材料に、AAE と普通の自己符号化器をあわせたようなモデルで学習させた.</p>
<p><span class="math inline">\((x, y)\)</span> について</p>
<figure>
<img src="img/aae/saae.png" />
</figure>
<p>手書き文字画像 <span class="math inline">\(x\)</span> を例に取ると、 <span class="math inline">\(G\)</span> は <span class="math inline">\(x\)</span> から何かしら <span class="math inline">\(\text{fake }z = G(x)\)</span> を生成し、 ラベル <span class="math inline">\(y\)</span> (例えば one-hot ベクトルとする) と結合したものから Decoder は元の画像 <span class="math inline">\(x\)</span> を復元しようとする. 書くべき数字はラベルから分かるので、 <span class="math inline">\(G(x)\)</span> はその他の成分、style と言われる.</p>
<h3 id="semi-supervised-aae">Semi-supervised AAE</h3>
<p>style を求める <span class="math inline">\(G\)</span> にクラス予測も一緒にさせる. つまり、<span class="math inline">\((\text{style}, y&#39;) = G(x)\)</span> とする. ただしクラス予測は MSE とか取るんじゃなくて、何故か知らんけどここも、<span class="math inline">\(P(y|x)\)</span> から取った <span class="math inline">\(y\)</span> と識別させるようにする. つまり全体として GAN 2つをくっつけた.</p>
<figure>
<img src="img/aae/ssaae.png" />
</figure>
<p>だんだんゴツくなってきたな...</p>
<h3 id="unsupervised-clustering-with-aae">Unsupervised Clustering with AAE</h3>
<p><span class="math inline">\(m\)</span> クラスにクラスタリングしたいとき、 <span class="math inline">\(y&#39; \in \mathbb{R}^m\)</span> になるように次のようなモデルを使う.</p>
<figure>
<img src="img/aae/clustering.png" />
</figure>
<p>元論文では MNIST を 16 classes (10 ではなく) にクラスタリングした結果を示している (Figure 9).</p>
<!--

  HTML として pandoc -B で include する.

  <H2> を列挙してそれらにリンクを貼った toc を id='toc' に埋め込む.
  markdown で書いてるだろうから例として次のような段落を書けばよい.

```
## INDEX
<div id=toc></div>
```

  used in
  - /memo/gnuplot
  - /memo/linux
  - /memo/imagemagick

-->
<script>
(function() {
  var sections = document.getElementsByTagName('h2');
  var i;
  var OL = document.createElement('ol');
  for (i=0; i < sections.length; ++i) {
    var LI = document.createElement('li');
    var A = document.createElement('a');
    A.innerHTML = sections[i].innerHTML;
    if (A.innerHTML.toUpperCase() == 'INDEX') continue;
    A.href = '#' + i;
    LI.appendChild(A);
    OL.appendChild(LI);

    var PREF = document.createElement('a');
    PREF.name = i;
    sections[i].appendChild(PREF);
  }

  var done = false;
  function work() {
    if (done) return;
    if ( document.getElementById('toc') === null) return; // no toc element
    document.getElementById('toc').appendChild(OL);
    done = true;
  };

  window.onload = work;
  setTimeout(work,800);
}());
</script>
</body>
</html>
