<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>BPR: Bayesian Personalized Ranking from Implicit Feedback</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../resources/css/c.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o" style="position:absolute; left:0.4em; top:0.4em; width:1.3em;border-radius:0.8em;"></i></a>
</header>
<header>
<h1 class="title">BPR: Bayesian Personalized Ranking from Implicit Feedback</h1>
</header>
<ul>
<li>
original paper: <a href=https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf>https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf</a>
</li>
</ul>
<div class="is-pulled-right">
<p><a class='tag is-blue' href=index.html#推薦システム>推薦システム</a> <a class='tag is-blue' href=index.html#行列分解>行列分解</a></p>
</div>
<h2 id="implicit-feedback">Implicit Feedback</h2>
<p>ユーザーにアイテムを推薦するモデルを教師あり学習で構成することを考える. この学習データとしてユーザーから明示的に与えられるアイテムごとのレーティングを Explicit Feedback というのに対して, そうでないものを Implicit Feedback という. 例えば購入履歴や視聴履歴である. これらは明示的にレーティングの量を言っていないし, 仮にポジティブに扱うしかなく, ネガティブデータが与えられない (Pisitive-Unlabeled Data). 仕方がないので, よくある方法としては, 購入してない, 視聴してないアイテムの中からランダムにいくつかサンプリングしてきたものをネガティブとして扱うのが普通 (Negative Sampling). アイテム空間は普通膨大で, そのほとんどはユーザーにとって興味のないネガティブなものである確率が高いという仮定による.</p>
<h2 id="personalized-ranking">Personalized Ranking</h2>
<p>ユーザー集合 <span class="math inline">\(U\)</span>, アイテム集合 <span class="math inline">\(I\)</span> に対して, Implicit Feedback とは <span class="math inline">\(S \subset U \times I\)</span> のこと.</p>
<p>ここで Personalized Ranking は各ユーザー <span class="math inline">\(u \in U\)</span> ごとに <span class="math inline">\(I\)</span> の上の全順序 <span class="math inline">\(&lt;_u\)</span> を定めるタスクを言う.</p>
<h3 id="notation">notation</h3>
<ul>
<li><span class="math inline">\(I_u^+ := \{ i \in I \mid (u,i) \in S\}\)</span></li>
<li><span class="math inline">\(I_u^- := I \setminus I_u^+\)</span></li>
<li><span class="math inline">\(U_i^+ := \{ u \in U \mid (u,i) \in S\}\)</span></li>
<li><span class="math inline">\(U_i^- := U \setminus U_i^+\)</span></li>
</ul>
<p>さて, 先に述べたように <span class="math inline">\(U \times I\)</span> の内, <span class="math inline">\(S\)</span> を正例とし, <span class="math inline">\(U \times I\)</span> を擬似的に負例にするのだが, もしこれらに完全にフィッティングさせた場合は, <span class="math inline">\(S\)</span> へ属するかどうかを判定する機械にしかならない. そのために正則化を入れるなど汎化性能を担保するテクが必ず必要.</p>
<p>さてランキング（すなわち全順序）を pair-wise に学習することを考える. ランキングのためのデータセットは次のようになる: <span class="math display">\[D_S = \{ (u, i, j) \mid u \in U, i \in I_u^+, j \in I_u^- \}\]</span> これはもちろん <span class="math inline">\(i &gt;_u j\)</span> を表している.</p>
<h3 id="bayesian-personalized-ranking-bpr">Bayesian Personalized Ranking (BPR)</h3>
<p>確率 <span class="math inline">\(P(i &gt;_u j \mid \Theta)\)</span> を尤度にベイズ推定してく.</p>
<p><span class="math display">\[\begin{align*}
P(&gt; \mid \Theta)
&amp; = \prod_u P(&gt;_u \mid \Theta) \\
&amp; = \prod_u
    \left[ \prod_{(i,j) \in I_u^+} P(i &gt;_u j \mid \Theta)
        \times \prod_{(i,j) \in I_u^-} \left( 1 - P(i &gt;_u j \mid \Theta) \right)
    \right] \\
&amp; = \prod_{(u,i,j) \in D_s} P(i &gt;_u j \mid \Theta) ~~~~~~~~\cdots(\text{!}) \\
P(\Theta \mid &gt;) &amp; \propto P(&gt; \mid \Theta) P(\Theta)
\end{align*}\]</span></p>
<p>(!) のところは <span class="math inline">\(D_s\)</span> が性質の良い部分集合であることを仮定してる気がする. 少なくとも近似だと思う.</p>
<p>シグモイド関数 <span class="math inline">\(\sigma\)</span> を用いると確率は適当な値 <span class="math inline">\(x\)</span> を以て, <span class="math display">\[P(i &gt;_u j \mid \Theta) = \sigma\left(x_u^{ij}(\Theta)\right)\]</span> と表せる. この <span class="math inline">\(x\)</span> を推定することにする. これを入れて, さっきの式の対数をとると, <span class="math display">\[O := \log P(\Theta \mid &gt;) = \sum_{(u,i,j) \in D_s} \log \sigma(x_u^{ij}) + \log P(\Theta)\]</span> これを最大化する <span class="math inline">\(\Theta\)</span> を探索すればよい.</p>
<h3 id="bpr-learning">BPR Learning</h3>
<p>さっきの <span class="math inline">\(O\)</span> を微分して勾配法をする.</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial O}{\partial \Theta}
&amp; = \sum_{(u,i,j) \in D_s} \frac{\partial}{\partial \Theta} \log \sigma(x_u^{ij}) + \frac{\partial}{\partial \Theta} \log P(\Theta) \\
&amp; = \sum_{(u,i,j) \in D_s} (\sigma(x_u^{ij}) - 1) \frac{\partial x_u^{ij}(\Theta)}{\partial \Theta} + \frac{\partial}{\partial \Theta} \log P(\Theta) \\
\end{align*}\]</span></p>
<p>ここで, 最後の <span class="math inline">\(+ \log P(\Theta)\)</span> 及びその微分 <span class="math inline">\(+\frac{\partial}{\partial \Theta} \log P(\Theta)\)</span> はいわゆる罰則化項に対応している. ここは具体的に与えることは出来ないので, 例えば適当に <span class="math inline">\(\log P(\Theta) = - \lambda \| \Theta \|^2\)</span> などとして計算する.</p>
<h2 id="行列分解への適用">行列分解への適用</h2>
<p><span class="math inline">\(x\)</span> に関して次のようにモデル化をする.</p>
<ul>
<li><span class="math inline">\(x_u^{ij} := x_u^i - x_u^j\)</span></li>
<li><span class="math inline">\(x_u^i := w_{uk} h^{ki}\)</span>
<ul>
<li>ここで <span class="math inline">\(w_u, h^i\)</span> はそれぞれ同じ長さの実ベクトルで, これの内積を取っている</li>
</ul></li>
</ul>
<p><span class="math inline">\(w_{uk}, h^{ki}\)</span> は全体としては二次元ベクトルで, 行列 <span class="math inline">\(W, H\)</span> によって与えることが出来る. モデルのパラメータはこれが全てなので, <span class="math display">\[\Theta = (W, H)\]</span> としてよい.</p>
<p>勾配を計算するのに <span class="math inline">\(\frac{\partial x_u^{ij}}{\partial \Theta}\)</span> が必要だが, これは</p>
<p><span class="math display">\[\begin{cases}
\frac{\partial x_u^{ij}}{\partial \Theta} = \frac{\partial x_u^i}{\partial \Theta} - \frac{\partial x_u^i}{\partial \Theta} \\
\frac{\partial x_u^i}{\partial w_{uk}} = h^{ki} \\
\frac{\partial x_u^i}{\partial h^{ki}} = w_{uk} \\
\end{cases}\]</span></p>
<p>これだけ.</p>
<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>
</body>
</html>
