<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Spherical Latent Spaces for Stable Variational Autoencoders</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../resources/css/c.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o" style="position:absolute; left:0.4em; top:0.4em; width:1.3em;border-radius:0.8em;"></i></a>
</header>
<header>
<h1 class="title">Spherical Latent Spaces for Stable Variational Autoencoders</h1>
</header>
<ul>
<li>
original paper: <a href=https://arxiv.org/abs/1808.10805>https://arxiv.org/abs/1808.10805</a>
</li>
</ul>
<div class="is-pulled-right">
<p><a class='tag is-blue' href=index.html#深層学習>深層学習</a> <a class='tag is-blue' href=index.html#オートエンコーダ>オートエンコーダ</a> <a class='tag is-blue' href=index.html#生成モデル>生成モデル</a></p>
</div>
<p><span class="math inline">\(\def\vMF#1#2{\mathrm{vMF}(#1, #2)}\)</span></p>
<h2 id="リンク">リンク</h2>
<ul>
<li><a href="https://arxiv.org/abs/1808.10805" class="uri">https://arxiv.org/abs/1808.10805</a></li>
<li><a href="https://github.com/jiacheng-xu/vmf_vae_nlp" class="uri">https://github.com/jiacheng-xu/vmf_vae_nlp</a></li>
</ul>
<h2 id="概要">概要</h2>
<p>潜在分布にガウシアン分布を用いた <a href="VAE.html">VAE</a> のデメリットとして, collapse してしまう現象に陥ってしまうことがあること. つまり encoder は入力を無視して最適な分布に写し, decoder は潜在分布を無視して平均的なデータを生成するような状態が期待しない局所的最適解として存在する.</p>
<p>この論文では, ガウシアン分布をやめて von Mises-Fisher (vMF) 分布を用いることで安定化を図る.</p>
<h2 id="vmf-分布">vMF 分布</h2>
<p><span class="math inline">\(x \in \mathbb R^d\)</span> に関する <span class="math inline">\(d\)</span> 次元 vMF 分布とは球面 <span class="math inline">\(S_{d-1}\)</span> の上の分布であって, その密度関数は次の <span class="math inline">\(f_d\)</span> で与えられる. ここで <span class="math inline">\(\mu \in \mathbb R^d, \kappa \in \mathbb R\)</span> がパラメータ. ただし制約として <span class="math inline">\(|\mu|=1, \kappa \geq 0\)</span> を要請する. また, <span class="math inline">\(I_v\)</span> は<a href="https://ja.wikipedia.org/wiki/%E3%83%99%E3%83%83%E3%82%BB%E3%83%AB%E9%96%A2%E6%95%B0#%E5%A4%89%E5%BD%A2%E3%83%99%E3%83%83%E3%82%BB%E3%83%AB%E9%96%A2%E6%95%B0">第一種変形ベッセル関数</a>.</p>
<p><span class="math display">\[f_d(x ; \mu, \kappa) = C_d(\kappa) \exp(\kappa \mu^T x)\]</span> <span class="math display">\[C_d(\kappa) = \frac{\kappa^{d/2-1}}{(2\pi)^{d/2} I_{d/2-1}(\kappa)}\]</span></p>
<h3 id="一様分布とのkl距離">一様分布とのKL距離</h3>
<p>パラメータ <span class="math inline">\(\mu, \kappa\)</span> での vMF 分布を <span class="math inline">\(\vMF{\mu}{\kappa}\)</span> と書くことにする. 一様分布は <span class="math inline">\(\vMF{\mu}{0}\)</span> で与えられる. <span class="math inline">\(\mu\)</span> は何でも良い. <span class="math inline">\(\vMF{\mu}{\kappa}\)</span> と一様分布とのKL距離が次で与えられる.</p>
<p><span class="math display">\[KL(\vMF{\mu}{\kappa} \| \vMF{\cdot}{0}) =
\kappa \frac{I_{d/2}(\kappa)}{I_{d/2-1}(\kappa)}
+ (d/2-1) \log \kappa
- d/2 \log(2\pi)
- \log I_{d/2-1}(\kappa)
+ d/2 \log(\pi) + \log 2 - \log \Gamma(d/2)\]</span></p>
<p><span class="math inline">\(\mu\)</span> は分布の平均？で, 一様分布との距離なので, <span class="math inline">\(\mu\)</span> には依存しない. <span class="math inline">\(\kappa\)</span> が大きくなるに単調に <span class="math inline">\(KL\)</span> も増加する.</p>
<h3 id="sampling">sampling</h3>
<p>VAE に使うためには vMF 分布から点をサンプリングする方法が必要. [Wood 1994] &quot;Simulation of the von mises fisher distribution&quot; の方法によると書いてあるが, これを読むには $5.00 必要なので諦める.</p>
<p>実装が公開されてるのだが, ちょうど <a href="https://github.com/jiacheng-xu/vmf_vae_nlp/blob/master/NVLL/distribution/vmf_only.py#L92">NVLL/distribution/vmf_only.py#L92</a> の部分で <span class="math inline">\(w\)</span> という乱数を <span class="math inline">\(\kappa, d\)</span> によって決める.</p>
<p>ベクトル <span class="math inline">\(\mu\)</span> とそれに直交するベクトルをランダムに <span class="math inline">\(v\)</span> として選んだ時 <span class="math display">\[w \mu + \sqrt{1-w^2} v\]</span> として, これを <span class="math inline">\(\vMF{\mu}{\kappa}\)</span> からサンプリングして得た点とする.</p>
<h2 id="vmf-vae">vMF VAE</h2>
<p>vMF を潜在分布として推定し, 先の方法でサンプリングした点からデータを復元するように VAE を構成する.</p>
<!--

  HTML として pandoc -B で include する.

  <H2> を列挙してそれらにリンクを貼った toc を id='toc' に埋め込む.
  markdown で書いてるだろうから例として次のような段落を書けばよい.

```
## INDEX
<div id=toc></div>
```

  used in
  - /memo/gnuplot
  - /memo/linux
  - /memo/imagemagick

-->
<script>
(function() {
  var sections = document.getElementsByTagName('h2');
  var i;
  var OL = document.createElement('ol');
  for (i=0; i < sections.length; ++i) {
    var LI = document.createElement('li');
    var A = document.createElement('a');
    A.innerHTML = sections[i].innerHTML;
    if (A.innerHTML.toUpperCase() == 'INDEX') continue;
    A.href = '#' + i;
    LI.appendChild(A);
    OL.appendChild(LI);

    var PREF = document.createElement('a');
    PREF.name = i;
    sections[i].appendChild(PREF);
  }

  var done = false;
  function work() {
    if (done) return;
    if ( document.getElementById('toc') === null) return; // no toc element
    document.getElementById('toc').appendChild(OL);
    done = true;
  };

  window.onload = work;
  setTimeout(work,800);
}());
</script>
</body>
</html>
