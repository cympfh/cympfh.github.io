<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="unidoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Deep Koalarization: Image Colorization using CNNs and Inception-ResNet-v2</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="https://cympfh.cc/resources/css/youtube.css" />
  <link href="https://unpkg.com/prismjs@1.x.0/themes/prism.css" rel="stylesheet" />
  <script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-chtml-full.js"></script>
  <link href="resources/css/c.css" rel="stylesheet" />
  <link href="../resources/css/c.css" rel="stylesheet" />
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />

</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o"></i></a>
</header>

<h1 class="title">Deep Koalarization: Image Colorization using CNNs and Inception-ResNet-v2</h1>
<p><ul> <li>original paper: <a href=https://www.researchgate.net/publication/321744935_Deep_Koalarization_Image_Colorization_using_CNNs_and_Inception-ResNet-v2>https://www.researchgate.net/publication/321744935_Deep_Koalarization_Image_Colorization_using_CNNs_and_Inception-ResNet-v2</a></li> </ul> <div class='is-pulled-right'> <a class='tag is-blue' href=index.html#深層学習>深層学習</a> <a class='tag is-blue' href=index.html#自動着色>自動着色</a> </div></p>
<h2>リンク</h2>
<ul>
  <li><a href="https://github.com/baldassarreFe/deep-koalarization/">ソースコード</a></li>
</ul>
<h2>概要</h2>
<p>自動着色を行う</p>
<h2>アプローチ</h2>
<p><code>CIE L*a*b</code> (CIELAB) 空間で色付を行う. 入力はこの <code>L</code> 部分だけのものだとして、着色というのは次のような \(\mathbb{R}_{\geq 0}\) 空間間の写像だとみなせる.</p>
\[X_L \in \mathbb{R}^{H \times W \times 1} \to (X_a, X_b) \in \mathbb{R}^{H \times W \times 2}\]
<p>これを以て、 \((X_L, X_a, X_b)\) を着色された画像として推論する.</p>
<h2>ネットワーク構造</h2>
<p><img src="https://i.imgur.com/fMxwe0d.png" alt="" /></p>
<h3>事前処理</h3>
<p>各ピクセルの値を \([-1,1]\) にする.</p>
<h3>Encoder</h3>
<p>\(H \times W\) の画像から \(H&#x2F;8 \times W&#x2F;8 \times 512\) の特徴ベクトルを得る.</p>
<h3>Feature Extractor</h3>
<p>こちらはより詳細な画像の特徴を取り出すためのもの ("underwater" "indoor" とか). 長さ \(1001\) の1次元ベクトルを得る.</p>
<p>Inception-ResNet-v2 を使いたいために、入力画像を 299x299 に拡大して、また3層に重ねることで、3チャンネルの 299x299x3 という画像を作って入力にする. また事前学習済みのものを利用する.</p>
<h3>Fusion</h3>
<p>Encoder の出力と Feature Extractor の出力とを結合する. Feature Extractor の出力を \(H&#x2F;8 \times W&#x2F;8\) 本だけ複製して並べるｋとおで \(H&#x2F;8 \times W&#x2F;8 \times 1001\) のベクトルを得る. これをEncoderの出力とそのまま結合することで \(H&#x2F;8 \times W&#x2F;8 \times (512+1001)\) のベクトルを得る.</p>
<p><img src="https://i.imgur.com/IAaxkUN.png" alt="" /></p>
<h3>loss</h3>
<p>mse</p>
<h2>実験</h2>
<h3>データセット</h3>
<p>ImageNet の中から 60k 枚だけを使う. ### 訓練 Adam で 23 時間. ### 結果 <img src="https://i.imgur.com/uEHgX8i.png" alt="" /></p>

<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>

  <script src="https://cympfh.cc/resources/js/youtube.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>