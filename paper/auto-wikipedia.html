<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="unidoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Automatically Generating Wikipedia Artciles: A Structure-Aware Approach (Sauper+, 2009)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="https://cympfh.cc/resources/css/youtube.css" />
  <link href="https://unpkg.com/prismjs@1.x.0/themes/prism.css" rel="stylesheet" />
  <script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-chtml-full.js"></script>
  <link href="resources/css/c.css" rel="stylesheet" />
  <link href="../resources/css/c.css" rel="stylesheet" />
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />

</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o"></i></a>
</header>

<h1 class="title">Automatically Generating Wikipedia Artciles: A Structure-Aware Approach (Sauper+, 2009)</h1>
<p><ul> <li>original paper: <a href=http://www.aclweb.org/anthology/P09-1024>http://www.aclweb.org/anthology/P09-1024</a></li> </ul> <div class='is-pulled-right'> <a class='tag is-blue' href=index.html#自然言語処理>自然言語処理</a> <a class='tag is-blue' href=index.html#自然言語生成>自然言語生成</a> <a class='tag is-blue' href=index.html#順序学習>順序学習</a> </div></p>
<h2>repo</h2>
<ul>
  <li><a href="https://github.com/csauper/wikipedia">github.com/csauper/wikipedia</a></li>
</ul>
<h2>Goal</h2>
<p>タイトルを入れると完全なWikipedia記事を生成する:</p>
<p>"3-M Syndrome" \(\mapsto\) complete article for Wikipedia</p>
<h2>感想</h2>
<ul>
  <li>"template-based" とあったから読んでみた</li>
  <li>思ってたのと違った</li>
</ul>
<h2>Overview</h2>
<ul>
  <li>
    entity の複数段落の要約 (overview)
    <ul>
      <li>原文 (段落) を <code>Yahoo!</code> からたくさん拾ってきて並べる</li>
    </ul>
  </li>
  <li>
    <code>+</code> content planning
    <ul>
      <li>テンプレートとして学習する</li>
    </ul>
  </li>
  <li>
    content に最適な文章を
    <ul>
      <li>perceptron ranking algorithm で学習</li>
      <li>整数線形計画法で選択</li>
    </ul>
  </li>
</ul>
<h2>Content Planning</h2>
<p>"Diseases" の content planning の例 (Figure 1):</p>
<p><img src="img/auto-wikipedia/fig1.jpg" alt="" /></p>
<p>template = topicの列:</p>
\[\text{[Diagnosis, Causes, Symptoms, Treatment]}\]
<h2>生成物</h2>
<ul>
  <li><a href="http://people.csail.mit.edu/csauper/?page_id=64">Automatically generated Wikipedia articles: people.csail.mit.edu/csauper/?page_id=64</a></li>
  <li>
    例えば
    <ul>
      <li><a href="https://en.wikipedia.org/wiki/3-M_syndrome">3-M Syndrome: en.wikipedia.org/wiki/3-M_syndrome</a></li>
    </ul>
  </li>
</ul>
<h2>生成物</h2>
<p>記事のフレーズでググるとまんまの文章が別なページから引っかかる (拾ってきてる)</p>
<p><img src="img/auto-wikipedia/google.jpg" alt="" /></p>
<p>生成したい文章に必要な文はネットのどこかにあると仮定する. ただし、</p>
<ol>
  <li>複数のページに散らばっている</li>
  <li>ノイズな文も含まれうる</li>
</ol>
<p>だから content planning が必要.</p>
<h2>Method Overview</h2>
<ol>
  <li>
    前処理
    <ul>
      <li>同じドメインの事例からテンプレート (トピックの列) の学習</li>
      <li>Search: 原文を集める</li>
    </ul>
  </li>
  <li>Selection Model: 原文を選ぶ</li>
  <li>選んだのを組み合わせる</li>
</ol>
<h2>Method::前処理::訓練事例</h2>
<p>訓練データとする文章をネットから集める</p>
<ul>
  <li>生成したい記事と近いドメインのもの</li>
  <li>実験では "Diseases" というドメインの他のWikipedia記事を用いた</li>
</ul>
\[\mathcal{D} = d_1, d_2 ~..~ d_n\]
<p>文章 \(d_i\) は複数段落 \(s\) ( <code>&lt;p&gt;</code> ) からなり、段落には見出し \(h\) ( <code>&lt;h*&gt;</code> ) がついてる.</p>
\[d_i = \left( h_i^j, s_i^j \right)_{j=1 .. m_i}\]
<h2>事前処理::テンプレート学習 (Section 3.1)</h2>
<p>見出しの列</p>
<ul>
  <li>\(h_1^1 \rightarrow h_1^2 \rightarrow \ldots \rightarrow h_1^m\)</li>
  <li>\(h_2^1 \rightarrow h_2^2 \rightarrow \ldots \rightarrow h_2^m\)</li>
  <li>\(~~~~~~~~~~~\vdots\)</li>
</ul>
<p>というのを template (topic列) だと見なして、 これを学習したい.</p>
<h2>事前処理::テンプレート学習 (Section 3.1)</h2>
<p>全見出し \(\{ h_i^j | i, j \}\) をクラスタリング \((t_1, t_2 .. t_k .. )\) して、 一つのクラスタ (多重集合) を topic とする.</p>
<ul>
  <li>\(t_1 \rightarrow t_3 \rightarrow \ldots \rightarrow t_m\)</li>
  <li>\(t_2 \rightarrow t_3 \rightarrow \ldots \rightarrow t_{m&#x27;}\)</li>
  <li>\(~~~~~~~~~~~\vdots\)</li>
</ul>
<p>みたいな列ができる.</p>
<ol>
  <li>この列の長さ \(k\) (平均長) の</li>
</ol>
<p>majority-order を計算して (majority ordering algorithm [Cohen+, 98] )、 template とする. 1. クラスタ \(t_j\) の要素の最頻の見出し \(h\) をクラスタの見だしとして用いる.</p>
<h2>事前処理 (誰か読んで)</h2>
<ul>
  <li>
    Repeated Bisectioning Algorithm [Zhao+, 05]
    <ul>
      <li>文章同士 \((s_i, s_j)\) のコサイン類似度を距離とした階層クラスタリング</li>
    </ul>
  </li>
  <li>
    Majority Ordering Algorithm [Cohen+, 98]
    <ul>
      <li>有向辺に遷移確率ぽい何かをつけた順序の最適化</li>
    </ul>
  </li>
</ul>
<p><img src="img/auto-wikipedia/order.jpg" alt="" /></p>
<h2>事前処理::Search: 作ったテンプレート毎に excerpts (抜粋) を拾う (Section 3.1)</h2>
<p>トピック \(t_j\) 毎に、できるだけたくさん excerpts を拾う</p>
<ol>
  <li>
    "記事タイトル (entity) + 見出し \(h\) ( \(h \in t\) )" で <code>Yahoo!</code> でググる
    <ul>
      <li>e.g. <code>&quot;3-M Syndrome&quot;+diagnosis</code></li>
    </ul>
  </li>
  <li>上位10ページ採用</li>
  <li>見出しと段落のペアを一つの excerpts として抽出</li>
</ol>
<p>平均で 6 excerpts/topic 取れた</p>
<h2>ここまで</h2>
<p>ドメイン (e.g. "Diseases") に対して、 テンプレート \(t_1 ... t_k\) . トピックごとに候補となる抜粋</p>
<ul>
  <li>\(t_1\) : \(e_{11}, e_{12} ~...~ e_{1r_1}\)</li>
  <li>\(t_2\) : \(e_{21}, e_{22} ~...~ e_{2r_2}\)</li>
  <li>\(~~~~~\vdots\)</li>
  <li>\(t_k\) : \(e_{k1}, e_{k2} ~...~ e_{kr_k}\)</li>
</ul>
<p>抜粋 を一つずつ選択していくことで、 最終的な記事を生成する. ただし、</p>
<ol>
  <li>coverage and redundancy のバランス</li>
  <li>ノイズを上手く避ける必要</li>
</ol>
<h2>Selection Model (Section 3.2.1)</h2>
<p>候補 excerpts から一つずつを選択するモデル</p>
<ul>
  <li>
    入力
    <ol>
      <li>記事タイトル</li>
      <li>トピックの列 \((t_1, \ldots,  t_k)\)</li>
      <li>トピック \(t_j\) に対して候補 \((e_j^k)_{k=1..r}\)</li>
    </ol>
  </li>
  <li>
    パラメータ
    <ol>
      <li>素性 \(\phi : e \mapsto \phi(e) \in \mathbb{R}^n\) (天から与えられる)</li>
      <li>\(t_j\) に対応する重み \(w_j \in \mathbb{R}^n\) (学習する)</li>
    </ol>
  </li>
</ul>
<h2>推定と学習</h2>
<ul>
  <li>
    \(w_j\) の学習: perceptron ranking algorithm
    <ul>
      <li>ドメイン-トピックに依存した重み</li>
    </ul>
  </li>
  <li>推定: 整数線形計画法 (ILP)</li>
</ul>
<h2>推定::Ranking</h2>
<p>トピック \(t_j\) に対して、excerpt \(e\) のスコアを</p>
\[score(e) = \phi(e) \cdot w_j\]
<p>で与える. 候補 \((e_1, e_2, \ldots, e_r)\) を、この score の高い順で並び替える.</p>
\[Rank(e_1 ~..~ e_r; w_j) = (e_1 ~..~ e_r)\]
<p>( \(e_\ell\) は \(\ell\) 番目に良い).</p>
<h2>推定::最適化</h2>
<p>ランキングで並び替えした後</p>
<ul>
  <li>\(t_1\) : \(e_{11}, e_{12} ~...~ e_{1r_1}\)</li>
  <li>\(t_2\) : \(e_{21}, e_{22} ~...~ e_{2r_2}\)</li>
  <li>\(~~~~~\vdots\)</li>
  <li>\(t_k\) : \(e_{k1}, e_{k2} ~...~ e_{kr_k}\)</li>
</ul>
\[\min \sum_j \sum_\ell \ell \cdot x_{j\ell}\]
<p>インディケータ \(x_{j\ell}\) は \(e_{j\ell}\) を選択するとき \(1\) 、さもなくば \(0\) .</p>
<p>制約 (ちょうど一つだけ選択すること):</p>
\[\sum_\ell x_{j\ell} = 1 ~ \forall j\]
<h2>推定::最適化::Redundancy Constraints</h2>
<p>内容の冗長性をできるだけ取り除く為の制約:</p>
\[(x_{j\ell} + x_{j&#x27; \ell&#x27;}) \cdot sim(e_{j\ell}, e_{j&#x27; \ell&#x27;}) \leq 1\]
<p>を加える.</p>
<p>ここで、 \(sim\) は文章同士の cos 類似度.</p>
<h2>推定::最適化::Solving the ILP</h2>
<ul>
  <li><code>lp_solve</code> は厳密解を与える (NP-hard)</li>
  <li>近似アルゴリズム: knapsack problem [McDonald, 07]</li>
</ul>
<h2>\(w_j\) の学習</h2>
<p>perceptron ranking algorithm に基づく.</p>
<h2>Perceptron Ranking Algorithm [Collins, 02] (蛇足)</h2>
<ul>
  <li>Max-Ent によるPOSタグ付け</li>
  <li>
    最上位のものを出力する代わりに
    <ul>
      <li>上位20を取って re-rank していくビームサーチ</li>
      <li>複数の候補から一番良いものを学習する</li>
    </ul>
  </li>
</ul>
<h2>The perceptron training for ranking</h2>
<ul>
  <li>
    入力
    <ul>
      <li>答え \(x_1\) , 他の候補 \(x_2, x_3 ~..~ x_k\)</li>
      <li>素性 \(\phi: x \mapsto \phi(x) \in \mathbb{R}^s\)</li>
      <li>スコア \(score(x,w) = w \cdot \phi(x)\)</li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    初期化
    <ul>
      <li>\(w^0 = 0 \in \mathbb{R}^s\)</li>
    </ul>
  </li>
  <li>
    For \(i=1,2 ~..~ n\)
    <ul>
      <li>\(j = \text{argmax}_j ~ score(x_j, w^{i-1})\)</li>
      <li>
        If \(j=1\)
        <ul>
          <li>Then \(w^i = w^{i-1}\)</li>
          <li>Else \(w^i = w^{i-1} + \phi(x_1) - \phi(x_j)\)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<h2>Update</h2>
<p>\(score(x_1, w) \lt score(x_j, w) (j\ne 1)\) のとき (Else節)、</p>
\[score(x_1, w) - score(x_j, w) = w \cdot (\phi(x_1) - \phi(x_j))\]
<p>を大きくすればよい.</p>
<ul>
  <li>Else \(w^i = w^{i-1} + \phi(x_1) - \phi(x_j)\)</li>
</ul>
<h2>voted perceptron (もっと蛇足)</h2>
<p>学習の経過で作られた \(w^1, w^2 ~..~ w^n\) を全て用いる.</p>
<ul>
  <li>
    入力
    <ul>
      <li>\(x_1, x_2 ~..~ x_k\)</li>
      <li>同じ素性 \(\phi: x \mapsto \phi(x)\)</li>
    </ul>
  </li>
  <li>
    初期化
    <ul>
      <li>長さ \(n\) の配列 <code>V[] = [0, 0, .. 0]</code></li>
    </ul>
  </li>
  <li>
    For \(i=1,2,..n\)
    <ul>
      <li>\(w^i\) で score が最上位の \(j = \text{argmax}_j score(x_j, w^i)\)</li>
      <li><code>V[i] += 1</code></li>
    </ul>
  </li>
  <li>出力 \(x_j\) where \(j = \text{argmax}_j V[j]\)</li>
</ul>
<h2>学習::Ranking Perceptron</h2>
<p>テンプレートを作る元文章からゴールドデータ \(s_1, s_2 ~..~ s_k\) を正解として用いる.</p>
<ul>
  <li>\(t_1\) : \(s_1\) ; \(e_{11}, e_{12} ~..~ e_{1r_1}\)</li>
  <li>\(t_2\) : \(s_2\) ; \(e_{21}, e_{22} ~..~ e_{2r_2}\)</li>
  <li>\(\vdots\)</li>
  <li>\(t_k\) : \(s_k\) ; \(e_{k1}, e_{k2} ~..~ e_{kr_k}\)</li>
</ul>
<ol>
  <li>Rank with \(w_j \mapsto (e_{j1} ~..~ e_{jr}) ~ \forall j\)</li>
  <li>Optimize as a ILP \(x_j = Opt(e_{j1} ~..~ e_{jr}) ~ \forall j\)</li>
  <li>
    If \(sim(s_j, x_j) \geq 0.8\)
    <ul>
      <li>Then \(w_j\) を更新しない</li>
      <li>Else \(w_j = w_j + \phi(s_j) - \phi(x_j)\)</li>
    </ul>
  </li>
</ol>
<h2>評価</h2>
<ol>
  <li>
    ROUGE-1
    <ul>
      <li>テストデータ (Wikipedia記事として既にあるもの) を訓練データ (Wikipedia記事)+Yahoo!(該当記事を参照しない) で生成してROUGEで比較</li>
    </ul>
  </li>
  <li>
    REACTIONS
    <ul>
      <li>実際にWikipediaに投稿してみんなの反応を見る</li>
    </ul>
  </li>
</ol>
<h2>データ</h2>
<ul>
  <li>
    ドメイン:
    <ul>
      <li>American Film Actors: 2150 articles in Wikipedia</li>
      <li>Diseases: 523</li>
    </ul>
  </li>
  <li>各ドメインの90% の文章を訓練とする.</li>
  <li>
    残り10%をテストとする
    <ul>
      <li>生成する際は、記事のタイトルだけを参照する</li>
    </ul>
  </li>
  <li>平均 4 topic (段落)</li>
  <li>Search 手続き (Yahoo!) 中ではテストデータ自体を参照しないようにする</li>
</ul>
<h2>Baselines</h2>
<ol>
  <li>
    Search
    <ul>
      <li>パーセプトロンでランキングせずに、検索結果で引っかかった順にランク付けを行う</li>
      <li>1ページから \(k\) 段落拾ってきた場合には、それをそのまま候補として用いる</li>
      <li>大抵、ページの一番初めの段落は comprehensive overview であるので summary としては優秀</li>
    </ul>
  </li>
  <li>
    NoTemplate
    <ul>
      <li>テンプレート (トピック列) を気にしない</li>
      <li>Search では、記事のタイトルだけで検索する (full model では記事タイトル+見出し)</li>
      <li>文の組合せ方は既存手法に従う [Zhou 04; Biadsy 08]</li>
    </ul>
  </li>
  <li>
    Disjoint
    <ul>
      <li>ILPを行わない</li>
      <li>ランキングの後、各トピックから1位のものだけを選択して組み合わせる</li>
    </ul>
  </li>
  <li>
    Oracle
    <ul>
      <li>候補からテストデータとコサイン類似度が高いものを選択する</li>
      <li>生成すべきテストデータを参照する上にROUGEで評価するので</li>
      <li>ランキングアルゴリズムに関する精度の上限を与えると考える</li>
    </ul>
  </li>
</ol>
<h2>ROUGE-1 結果 (Table 3)</h2>
<p><img src="img/auto-wikipedia/tab3.jpg" alt="" /></p>
<ul>
  <li>Oracle は上限</li>
  <li>No Template は一つのトピックに集中してしまう</li>
  <li>FullModel と Disjoint との差がランキングの良さ</li>
  <li>Search はまちまち. 良い記事を引けば良い</li>
</ul>
<h2>REACTIONS</h2>
<p>15の記事を投稿、5-11ヶ月放置</p>
<ul>
  <li>10 promoted from stubs to regular entries</li>
  <li>全ての記事が人手で編集された</li>
  <li>削除がなされた記事は無い</li>
  <li>記事中の三箇所 (1 section + 2 smaller pieces) が削除された</li>
</ul>
<p><img src="img/auto-wikipedia/tab4.jpg" alt="" /></p>
<ul>
  <li>The most common changes were small edits to formatting and introduction of links to other Wikipedia articles</li>
</ul>

<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>

  <script src="https://cympfh.cc/resources/js/youtube.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>