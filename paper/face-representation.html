<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Deep Learning Face Representation by Joint Identification-Verification (DeepID2)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../resources/css/c.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header class="page-header">
    <a href='index.html'><img src="../resources/img/identicon.png" style="position:relative; top:0.4em; width:1.3em;border-radius:0.8em;" /> paper/</a>
</header>
<header>
<h1 class="title">Deep Learning Face Representation by Joint Identification-Verification (DeepID2)</h1>
</header>
<ul>
<li>
original paper: <a href=https://arxiv.org/abs/1406.4773>https://arxiv.org/abs/1406.4773</a>
</li>
</ul>
<div class="is-pulled-right">
<p><a class='tag is-blue' href=index.html#距離学習>距離学習</a> <a class='tag is-blue' href=index.html#類似度学習>類似度学習</a> <a class='tag is-blue' href=index.html#顔認証>顔認証</a></p>
</div>
<ul>
<li>論文リンク: <a href="https://arxiv.org/abs/1406.4773" class="uri">https://arxiv.org/abs/1406.4773</a></li>
<li>関連資料: <a href="http://vision.ia.ac.cn/zh/senimar/reports/Siamese-Network-Architecture-and-Applications-in-Computer-Vision.pdf">Siamese-Network-Architecture-and-Applications-in-Computer-Vision.pdf</a></li>
</ul>
<h2 id="概要">概要</h2>
<ul>
<li>55x47x3 の顔の画像から、写っている人間を特定するタスク</li>
<li>教師アリ学習を行う
<ul>
<li>通常のマルチクラス分類に加えて、Siamese ネットワークの要領を加えている</li>
</ul></li>
</ul>
<h2 id="手法">手法</h2>
<p>入力 <span class="math inline">\(x\)</span> から、CNNを 4 つ重ねることで 160 次元の特徴ベクトル <span class="math inline">\(f_x\)</span> を得る. 彼らはこの特徴ベクトルを DeepID2 と呼んでいる. (version 2 の 2 らしい.)</p>
<h3 id="identify">Identify</h3>
<p>通常の、マルチクラス分類と同様のことを、DeepID2 <span class="math inline">\(f_x\)</span> から行う. すなわち、 入力 <span class="math inline">\(x\)</span> がクラス <span class="math inline">\(t\)</span> である確率を <span class="math inline">\(f_x\)</span> から求める関数を学習する.</p>
<ul>
<li>確率の予測
<ul>
<li><span class="math inline">\((f_x, t) \mapsto \hat{p_t}\)</span></li>
</ul></li>
<li>この予測器に関する目的関数はクロスエントロピー
<ul>
<li><span class="math inline">\(\text{Ident}(f_x, t) = - \sum_{t&#39;} p_{t&#39;} \log \hat{p_{t&#39;}} = - \log \hat{p_t}\)</span></li>
</ul></li>
</ul>
<h3 id="verify">Verify</h3>
<p>同時に、距離学習 (metrics learning) も、行う. すなわち、入力 <span class="math inline">\(x_1, x_2\)</span> から DeepID2 <span class="math inline">\(f_1, f_2\)</span> を得、この２つから、<span class="math inline">\(x_1, x_2\)</span> のラベルが同じかどうかを推定する. この推定は、ほとんど DeepID2 そのものを使う.</p>
<h4 id="l2-に基づく-verify">L2 に基づく Verify</h4>
<ul>
<li><span class="math inline">\((f_1, f_2) \mapsto \| f_1 - f_2 \|^2\)</span></li>
<li>目的関数は次の通り</li>
</ul>
<p><span class="math display">\[\text{Verify}(f_1, f_2) =
\begin{cases}
\frac{1}{2} \| f_1 - f_2 \|^2 &amp; \text{ when labels are same } \\
\frac{1}{2} \max(0, m - \| f_1 - f_2 \|^2) &amp; \text{ when different}
\end{cases}\]</span></p>
<p>すなわち、ラベルが等しいときは、DeepID2 の L2 距離が近くなるようにし、 等しくない場合は、マージン <span class="math inline">\(m\)</span> より離れるように学習する (ここは &quot;contrastive loss&quot; が使われてる).</p>
<p>別な種類の Verify も提案している.</p>
<h4 id="l1-に基づく-verify">L1 に基づく Verify</h4>
<ul>
<li><span class="math inline">\((f_1, f_2) \mapsto \sigma(b + w \cos(f_1, f_2))\)</span>
<ul>
<li><span class="math inline">\(\sigma\)</span> はシグモイド関数</li>
</ul></li>
<li>目的関数は次の通り</li>
</ul>
<p><span class="math display">\[\text{Verify}(f_1, f_2) =
\begin{cases}
\frac{1}{2} (1 - \sigma(b + w \cos(f_1, f_2)))^2 &amp; \text{ when labels are same } \\
\frac{1}{2} (\sigma(b + w \cos(f_1, f_2)))^2 &amp; \text{ when different}
\end{cases}\]</span></p>
<p>ここで <span class="math inline">\(b, w\)</span> は学習可能なパラメータ. <span class="math inline">\(\cos\)</span> の出力はスカラーなので、それを線形にちょっと加工するだけの簡素な活性ユニット.</p>
<h3 id="学習過程">学習過程</h3>
<p>Identify と Verify という2つの解き方を <span class="math inline">\(1 : \lambda\)</span> の割合で混ぜて学習する. この <span class="math inline">\(\lambda\)</span> は、初め <span class="math inline">\(0\)</span> からスタートして、学習の過程で徐々に、際限なく増やしていく.</p>
<p>すなわち、初めは単にマルチクラス分類問題として解き、徐々に、 Siamese Network になる.</p>
<h2 id="私の感想">私の感想</h2>
<p>既存手法を2つ混ぜたというだけだが、混ぜ方がこの論文の一番のミソだと思う.</p>
<p>本当は初めから単に Siamese Network にしたかったのだろう、と邪推する. あとから新しいラベル (つまり人物) の顔写真が新しくテストデータに追加されるとき、 マルチクラス分類では、予め用意していたラベルのどれかに振り分けることしかできないが、 Siamese Network では分類することが出来る.</p>
<p>しかし、いきなり Siamese Network を学習するのは難しい. 学習が全然安定しないからである. 私も何度も試したことがあるが、すぐに縮退 (degeneracy) という現象が起きてしまう. すなわち、ここでいう関数 <span class="math inline">\(x \mapsto f_x\)</span> が定数関数になってしまう. これを避けるのに事前学習などが有効であるが、強い最適化を掛けると、やはり縮退してしまう.</p>
<p>恐らく、<span class="math inline">\(\lambda\)</span> を徐々に上げるのは、事前学習を混合的に行っているのだと思う.</p>
<!--

  HTML として pandoc -B で include する.

  <H2> を列挙してそれらにリンクを貼った toc を id='toc' に埋め込む.
  markdown で書いてるだろうから例として次のような段落を書けばよい.

```
## INDEX
<div id=toc></div>
```

  used in
  - /memo/gnuplot
  - /memo/linux
  - /memo/imagemagick

-->
<script>
(function() {
  var sections = document.getElementsByTagName('h2');
  var i;
  var OL = document.createElement('ol');
  for (i=0; i < sections.length; ++i) {
    var LI = document.createElement('li');
    var A = document.createElement('a');
    A.innerHTML = sections[i].innerHTML;
    if (A.innerHTML.toUpperCase() == 'INDEX') continue;
    A.href = '#' + i;
    LI.appendChild(A);
    OL.appendChild(LI);

    var PREF = document.createElement('a');
    PREF.name = i;
    sections[i].appendChild(PREF);
  }

  var done = false;
  function work() {
    if (done) return;
    if ( document.getElementById('toc') === null) return; // no toc element
    document.getElementById('toc').appendChild(OL);
    done = true;
  };

  window.onload = work;
  setTimeout(work,800);
}());
</script>
</body>
</html>
