<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ja" xml:lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="description" content="推論の圏 予測の合成" />
  <meta name="og:url" content="http://cympfh.cc/taglibro">
  <meta name="og:title" content="Thu Jan 20 2022" />
  <meta name="og:description" content="推論の圏 予測の合成" />
  <meta name="og:image" content="http://cympfh.cc/resources/img/identicon.png" />
  <meta property="og:url" content="http://cympfh.cc/taglibro">
  <meta property="og:title" content="Thu Jan 20 2022" />
  <meta property="og:description" content="推論の圏 予測の合成" />
  <meta property="og:image" content="http://cympfh.cc/resources/img/identicon.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@cympfh" />
  <meta name="generator" content="unidoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Thu Jan 20 2022</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
  </style>
  <link rel="stylesheet" href="../../resources/css/c.css" />
  <link rel="stylesheet" href="../../../resources/css/c.css" />
  <link rel="stylesheet" href="../../../resources/css/youtube.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" />
  <link href="https://unpkg.com/prismjs@1.x.0/themes/prism.css" rel="stylesheet" />
  <script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <div class="taglibro">
    <header class="page-header"><a href='../../index.html'><i class="fas fa-fast-backward"></i></a></header>
<h1 class="title">Thu Jan 20 2022</h1>
<p>\(\def\Hom{\mathrm{Hom}}\) 日本において Coinhive が合法化された. ここが EU なら, ユーザーに許可を取る限りで合法だとなっていたはずだ. ユーザーの意図に反してユーザーのデバイス資源を占有するプログラムであって, そして提供側が利益を得るという点で, web 広告と比較されがちだ. 産業になってしまったものは誰も今から違法化するわけにいかない. 日本が海外から見れば児童ポルノだと言われるようなイラストを取ってつけたゲームを許してるのも, 日本の産業になってしまったからだと思われる.</p>
<p>といった文章を書くことで日記の体裁を保った. 以下駄文.</p>
<h2>推論の圏</h2>
<h3>推論</h3>
<p>最終的にやりたいことは推論だ.</p>
<ul>
  <li>対象は（ありとあらゆる）集合</li>
  <li>入力（特徴量） \(A\) から, 出力（ラベル集合） \(B\) を推論する操作を \(A \to B\) と書く</li>
</ul>
<p>推論という操作は大雑把には写像だ. MNIST というデータセットは 28x28 の白黒画像に手書きした数字 (0-9) が1つ書かれている.</p>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST database - Wikipedia</a></li>
</ul>
<p>一枚の画像が入力として与えられるから, 書かれてる数字を推論せよという問題がある. 28x28 の画像は（画像という構造を忘れて）便宜的に \(\{0,1\}\) が \(784 = 28 \times 28\) 個並んだものとすれば,</p>
<ul>
  <li>\(A = \{ 0,1\}^{784}\)</li>
  <li>\(B = \{ 0,1,2,\ldots, 9 \}\)</li>
</ul>
<p>これがこの推論における入出力になる. \(a \in A\) が与えられたとき, ちょうど１つの \(b \in B\) を与えるとしてよい. \(B\) の上の確率分布を与えるようなものとしてもよい（この二つに本質的な差は内容に思える）. ここでは単に写像として書く.</p>
<p>さて \(A,B\) があったときに, その間に写像さえあればいくらでも推論を作る事ができる. どんな入力に対しても \(0 \in B\) を予測するようなものも推論ではある. もちろん我々が欲しいのは, 良い推論である. 推論の良し悪しというのは普通データセットの上で定量的に評価する. 適当に用意した推論 \(f \colon A \to B\) があったときに, それより良い推論 \(f&#x27;\) があるかどうか, あるならどうすれば手に入るかを考えるのは自然だ.</p>
<p>さて以上のようにありとあらゆる集合を対象にして, その間のありとあらゆる推論を射とする圏を <strong>推論の圏</strong> と呼ぶことにする.</p>
<h3>予測モデル</h3>
<p>個々のやりたい推論に対して, 良さそうな推論を緻密に構築するのは難しい. しかしながら, 推論 \(f \colon A \to B\) から \(f\) から具体的なパラメータだけを分離した \(\overline{f}\) は構成が容易だ. この \(\overline{f}\) を推論 \(f\) のための <strong>予測モデル</strong> という. とり得るパラメータ空間を \(P\) とすれば, 推論</p>
\[f \colon A \to B\]
<p>に対して</p>
\[\overline{f} \colon A \times P \to B\]
<p>と書こう. なぜこのような \(\overline{f}\) を構成するのが簡単かといえば, 一般に \(\mathbb R^M \to \{0,1,\ldots,N-1\}\) といった形式の推論のための予測モデルはすでにいくらでも提案されており, 書籍やインターネットで手に入るからである. 上記の \(M, N\) を今回の \(A,B\) に沿うように調整するだけでよい.</p>
<p>普通,</p>
\[\overline{f} \colon A \times P \to B\]
<p>があったら \(\overline{f}\) を予測モデル, \(A\) を入力, \(P\) をパラメータと呼ぶが, しかしそのような意味付けはプログラマ（人間）のための便宜上のものに過ぎない. 推論の圏においては \((A \times P)\) から \(B\) を予測する推論でしかない.</p>
<p>この形式の推論（予測モデル）では, 射 \(\overline f\) を採用すると一度決めたら, 「良い推論を探す」とは「良いパラメータ \(p \in P\) を探す」ことにほかならない. この操作のことを <strong>学習</strong> という.</p>
<p>定数 \(p \in P\) のことを単集合 \(I = \{\ast\}\) からの射 \(p \colon I \to P\) と同一視すれば,</p>
\[f \circ (1_A \times p) \colon A \to B\]
<p>がシンプルに \(A\) から \(B\) への推論になる. この合成を「パラメータを \(p\) で固定する」という.</p>
<h3>教師データ</h3>
<p>学習に必要な道具について考える. 推論 \(A \to B\) を得るためには, \(a \in A\) については \(b \in B\) を（あるいは確率分布を）予測すべきという教師データが必要である.</p>
<ul>
  <li>
    教師データとは（小さな）部分集合
    <ul>
      <li>\(\mathcal D \subset A \times B\)</li>
    </ul>
  </li>
</ul>
<p>もし全ての \(a \in A\) に対して教師データが用意されているなら, コレ自体を良い推論として使うことができる. しかし, 教師データとして与えられたものだけそれを使って推論して, 与えられていない場合には代わりに \(\bot\) を出力する推論が構築できる.</p>
\[\Delta \colon A \to B \cup \{\bot\}\]
\[\Delta(a) = \begin{cases} b    &amp; \text{ if } (a,b) \in D \\ \bot &amp; \text{ else } \\ \end{cases}\]
<p>この定義は \(a\) が重複して含まれてる場合を考慮してないといった問題があるが細かいことは省く.</p>
<p>\(\Delta\) のことも \(\mathcal D\) と同様に単に教師データと呼ぶことにする.</p>
<h3>生成</h3>
<p>推論 \(f \colon A \to B\) に対して, 推論</p>
\[g \colon B \to A\]
<p>であって,</p>
\[f \circ g = 1_B\]
<p>なるような \(g\) を \(f\) に対する生成と呼ぶ（ \(1_B\) は恒等射）.</p>
<p>もし \(f\) の生成があれば, そのようなものの1つを \(f^\top\) と書く.</p>
<p>特に, 教師データ \(\mathcal D\) による推論 \(\Delta\) については, 簡単にその生成 \(\Delta^\top\) が構築できる.</p>
<p>以下では一般の推論 \(f\) から生成 \(f^\top\) が構築できるとする.</p>
<h3>誤差伝播に基づいた学習</h3>
<p>深層学習における具体的な方法をここで述べることはしない. 圏のレベルでは, 次の操作があるということだけ言うことにする.</p>
<p>二つの推論 \(f,g \colon A \to B\) について,</p>
\[L \colon \Hom(A, B) \times A \times \Hom(A, B) \to A\]
<p>がある.</p>
<p>ここで \(\Hom(X,Y)\) とは \(X\) から \(Y\) への推論の集合を表す.</p>
<p>これは何をやりたいかというと, \(f(a)\) の値が \(g(a)\) の値に近づくような, \(a&#x27; = L(f,a,g)\) を \(a\) の周りで探す操作であることを期待している.</p>
<ul>
  <li>
    予測モデル
    <ul>
      <li>\(\overline f \colon A \times P \to B\)</li>
    </ul>
  </li>
  <li>
    学習データ
    <ul>
      <li>\(\Delta \colon A \to B\)</li>
    </ul>
  </li>
</ul>
<p>があるとき, 型を揃えるために, \(\Delta \circ \pi_1 \colon A \times P \to B\) を用意すれば,</p>
\[L(\overline f, -, \Delta \circ \pi_1) \colon A \times P \to A \times P\]
<p>が得られる. 便宜的にこれを</p>
\[\overline f \triangleleft \Delta ~ \colon ~ A \times P \to A \times P\]
<p>と書こう.</p>
<p>これの \(\to P\) だけ抽出して,</p>
\[\pi_2 \circ ( \overline f \triangleleft \Delta ) ~ \colon ~ A \times P \to P\]
<p>とすれば, これがパラメータ更新の操作になっている.</p>
<ul>
  <li>
    HILL CLIMBING LEARNING ALGORITHM:
    <ol>
      <li>データセット \(\mathcal D\) を用意する</li>
      <li>予測モデル \(\overline f\) を決定する</li>
      <li>パラメータ \(p \in P\) はランダムに初期化する</li>
      <li>
        Until 十分に良い推論になるまで
        <ul>
          <li>\(a \in A\) を上手にサンプリングしてくる</li>
          <li>\(p \leftarrow \pi_2(\overline{f} \triangleleft \Delta)(a, p)\)</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>
<p>ただし \(\bot\) の分は上手に無視することにする.</p>
<h2>予測の合成</h2>
<p>ここまでの説明では, ちょうど1つの予測モデルで最初の入力から最後の出力を推論していた. 実際にはこの推論は複数に分解してもよい. これは, パラメータの探索空間が狭まるとか実用上の効果がある.</p>
<p>MNIST の例で A, B の間に C という余計な空間を挟む. 例えば \(M\) 次元ユークリッド空間などである.</p>
<ul>
  <li>\(A = \{ 0,1\}^{784}\)</li>
  <li>\(C = \mathbb R^M\)</li>
  <li>\(B = \{ 0,1,2,\ldots, 9 \}\)</li>
</ul>
<p>予測 \(A \to B\) を作るのに, 予測 \(f \colon A \to C\) と \(g \colon C \to B\) をそれぞれ作って, これの合成 \(g \circ f\) として構築することを考える.</p>
<p>予測モデルを使う場合はそれぞれに</p>
<ul>
  <li>予測モデル \(\overline f \colon A \times P \to C\)</li>
  <li>予測モデル \(\overline g \colon C \times Q \to B\)</li>
</ul>
<p>を与える必要がある. この合成は,</p>
\[\overline{g} \circ \overline{f} \colon A \times (P \times Q) \to B\]
<p>として動く.</p>
<h3>学習</h3>
<p>やればできる.</p>
<ul>
  <li>教師データ \(\Delta \colon A \to B\)</li>
  <li>ランダムなパラメータ \(p \in P, q \in Q\) で初期化</li>
  <li>
    以下ループ
    <ul>
      <li>
        \(f_p = \overline f \circ (1_A \times p) \colon A \to C\) を信用して \(\overline g\) を学習する
        <ul>
          <li>\(\Delta \circ f_p^\top \colon C \to B\) を教師データだとして,</li>
          <li>\(\overline{g} \triangleleft (\Delta \circ f_p^\top)\) で \(q \in Q\) をアップデート</li>
        </ul>
      </li>
      <li>
        \(g_q\) を信用して
        <ul>
          <li>\((g_q \triangleleft f_p^\top) \circ f_p \colon A \to C\) を教師データとして,</li>
          <li>\(\overline{f} \triangleleft \cdots\) で \(p \in P\) をアップデート</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

    <footer>
      <p class="is-pulled-right">@cympfh / mail@cympfh.cc</p>
    </footer>
  </div>
  <script src="../../../resources/js/youtube.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>
  <script src="../../../resources/js/toc.js"></script>
</body>
</html>
