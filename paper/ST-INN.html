<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="unidoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>[1805.06447] Spatial Transformer Introspective Neural Network</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="https://cympfh.cc/resources/css/youtube.css" />
  <link href="https://unpkg.com/prismjs@1.x.0/themes/prism.css" rel="stylesheet" />
  <script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-chtml-full.js"></script>
  <link href="resources/css/c.css" rel="stylesheet" />
  <link href="../resources/css/c.css" rel="stylesheet" />
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />

</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o"></i></a>
</header>

<h1 class="title">[1805.06447] Spatial Transformer Introspective Neural Network</h1>
<p><ul> <li>original paper: <a href=https://arxiv.org/abs/1805.06447>https://arxiv.org/abs/1805.06447</a></li> </ul> <div class='is-pulled-right'> <a class='tag is-blue' href=index.html#深層学習>深層学習</a> <a class='tag is-blue' href=index.html#画像認識>画像認識</a> <a class='tag is-blue' href=index.html#データ水増し>データ水増し</a> <a class='tag is-blue' href=index.html#正則化>正則化</a> <a class='tag is-blue' href=index.html#GAN>GAN</a> </div></p>
<p>誤植っぽいのが多い? pdfのスタイルも悪いし、読みにくい.</p>
<h2>概要</h2>
<p>広大な画像の空間について、限られたデータセットでいかにして頑強なモデルを作るか. 画像を回転させて伸縮させるような、普通のデータ水増しはそのための一つの解決策であるが、いくらでもある画像のバリエーションに対して限界がある. 見たことのない未知のバリエーションを作りたい. モデルを騙そうとするGANを取り付けるのも、また一つの解決策である. これはどんどん未知の画像を生成しようとする. Introspective Neural Network (INN) は考え方はこれに近い. しかし、提案する Spatial Transformer (ST) を取り付けることで実装する INN は GAN と違って計算が一続きになっているので、一つの逆伝播で学習が可能で、普通の勾配最適化による学習が容易であるそうだ (GANだと敵対する部分で伝播が途切れるので).</p>
<h2>手法</h2>
<h3>Introspective Learning</h3>
<p>二値分類 \((X=\mathbb R^m) \to (Y=\{-1,+1\})\) について、 <a href="Tu-Generative.html">Tuの生成モデル</a> を使って、 分類器 \(q_t(y|x)\) と、疑似負例生成モデル \(p^-_t(x|y=-1)\) を反復的に学習していく.</p>
<p>分類器 \(q_t\) は CNN で組む. 彼らはどうも "Wasserstein Introspective Neural Networks" みたいなことがしたいらしいので、単に分類する他に wasserstein 距離の計算もこいつに持たせる. すなわち、</p>
\[f: X \to Y \times \mathbb R\]
<p>という機械 \(f\) を構成する.</p>
<p>\(f(x)\) の第一成分 ( \(Y\) 部分) を \(f_C(x)\) と、第二成分 ( \(\mathbb R\) 部分) を \(f_w(x)\) と書く. \(x, x&#x27;\) の wasserstein 距離は \(f_w(x) - f_w(x&#x27;)\) と計算される (ように学習する).</p>
<blockquote>\(f, f_C, f_w\) には共通のパラメータ \(\theta\) があるので \(f(x;\theta), f_w(x;\theta)\) などと書くのが正確だが、省略する.</blockquote>
<h3>Spatial Transformer</h3>
<p>入力画像をパラメータ \(\tau\) の下でアフィン変換する操作を \(T( - ; \tau)\) と書く. 具体的には次のような操作である</p>
\[\left[\begin{array}{c}
x^s \\ y^s
\end{array}
\right] =
\left[\begin{array}{ccc}
\tau_{11} &amp; \tau_{12} &amp; \tau_{13} \\
\tau_{21} &amp; \tau_{22} &amp; \tau_{23} \\
\end{array}\right]
\left[\begin{array}{c}
x^t \\ y^t \\ 1
\end{array}\right]\]
<p>元画像の座標 \((x^s, y^s)\) にあるピクセルを、変換後の座標 \((x^t, y^t)\) に割り当てる.</p>
<h3>分類器の学習</h3>
<p>分類器を学習する. 普通の教師あり学習のように正例と負例として \(S^+, S^-\) があるとする.</p>
<p>正例については普通のロスを設計する. ただし \(T\) による変換した画像についても正しく分類できるようにする. 定数 \(t_1, t_2\) を以て</p>
\[t_1 \times L(f_C(x^+)) + t_2 \times L(f_C(T(x^+; \tau)))\]
<p>\(L\) はなんか損失関数？かな.</p>
<p>次に、負例を用いて、wasserstein 距離を学習させる. 正例の分布と負例の分布の距離 \(f_w(x^+) - f_w(x^-)\) を最大化するのと、 あと wasserstein 距離が wasserstein 距離であるために \(f_w\) の傾きが 1 未満である必要がある. というわけで次を損失 (最小化) に加える:</p>
\[t_3 \times \left[ f_w(x^-) - f_w(x^+) + \lambda \left( \| \nabla f_w(\hat{x}) \| - 1 \right)^2 \right]\]
<p>いやこれだと傾きがちょうど1であることのが正しいことになるけど、、まあいいのかな？</p>
<p>以上2つの和を \(L_D(\theta)\) と書いて分類器の学習のための損失関数とする. ただし \(x^+, x^-\) は \(S^+, S^-\) からサンプリングされてきたもの. \(\hat{x}\) は正例と負例の中間点をランダムに選ぶとある.</p>
<h3>Transformer の学習</h3>
<p>Transformer の役割は、分類器にとって難しいデータのバリエーションを与えることなので、分類器にとっての損失を最大化させればよい. というわけで次を損失関数にする.</p>
\[L_{stn}(\tau) = -L(f_C(T(x^+; \tau)))\]
<h3>負例の増強</h3>
<p>学習した疑似負例生成モデル \(p^-_t\) を用いて \(S^-\) を増強する. \(p^-_t\) からいくらか疑似負例を集めて \(Z\) を作って</p>
\[S^- \leftarrow S^- \cup Z\]
<h3>全体の流れ</h3>
<ul>
  <li>
    以下を収束まで繰り返す
    <ul>
      <li>適当回数だけ分類器を学習</li>
      <li>Transformer を学習</li>
      <li>負例の増強</li>
    </ul>
  </li>
</ul>

<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>

  <script src="https://cympfh.cc/resources/js/youtube.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>