<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Collaborative Filtering for Implicit Feedback Datasets (Weighted Regularized Matrix Factorization)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../resources/css/c.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o" style="position:absolute; left:0.4em; top:0.4em; width:1.3em;border-radius:0.8em;"></i></a>
</header>
<header>
<h1 class="title">Collaborative Filtering for Implicit Feedback Datasets (Weighted Regularized Matrix Factorization)</h1>
</header>
<ul>
<li>
original paper: <a href=http://yifanhu.net/PUB/cf.pdf>http://yifanhu.net/PUB/cf.pdf</a>
</li>
</ul>
<div class="is-pulled-right">
<p><a class='tag is-blue' href=index.html#推薦システム>推薦システム</a> <a class='tag is-blue' href=index.html#行列分解>行列分解</a></p>
</div>
<h2 id="概要">概要</h2>
<p>協調レコメンドである行列分解に正則化と重み付けを足した.</p>
<p><a href="https://arxiv.org/pdf/1810.01520.pdf">RecSys2018 Spotify チャレンジ</a> で spotif.ai というチームが用いていた.</p>
<h2 id="手法">手法</h2>
<h3 id="通常の行列分解">通常の行列分解</h3>
<p><span class="math inline">\(m\)</span> ユーザーと <span class="math inline">\(n\)</span> アイテムがあって, 既に何かしらの指標 <span class="math inline">\(r_{ui}\)</span> が各ユーザー <span class="math inline">\(u\)</span>, アイテム <span class="math inline">\(i\)</span> ごとにある. この指標は例えば視聴したとか購入したとかで, <span class="math display">\[p_{ui} = \begin{cases}1 &amp; \text{ if } r_{ui} &gt; 0 \\ 0 &amp; \text{ otherwise}\end{cases}\]</span> と量化して使う. この <span class="math inline">\(p\)</span> を学習データにして <span class="math inline">\(p\)</span> を予測する.</p>
<p>ここで普通のよくある行列分解では潜在ベクトル次元を <span class="math inline">\(f\)</span> として, ユーザーベクトル <span class="math inline">\(X \in \mathbb R^{m \times f}\)</span> と アイテムベクトル <span class="math inline">\(Y \in \mathbb R^{n \times f}\)</span> を作る. それぞれの行ベクトルを <span class="math inline">\(x_u, y_i\)</span> などと書くことにする.</p>
<p>ここで <span class="math inline">\(x_u^T y_i\)</span> が <span class="math inline">\(p_{ui}\)</span> になるようなものを目指す. したがって損失関数が次で与えられる. <span class="math display">\[\mathcal L = \sum_{u,i} \| p_{ui} - x_u^T y_i \|^2\]</span></p>
<h3 id="正則化">正則化</h3>
<p>ここで <span class="math inline">\(x_u, y_i\)</span> をL2正則化することが考えられる. <span class="math display">\[\mathcal L = \sum_{u,i} \| p_{ui} - x_u^T y_i \|^2 + \lambda \left( \|x_u\|^2 + \|y_i\|^2 \right)\]</span></p>
<h3 id="重み付け">重み付け</h3>
<p>彼らは更にこの第一項のところに重みをつけた. <span class="math inline">\(p\)</span> は <span class="math inline">\(r\)</span> を量化して作ったが, <span class="math inline">\(r\)</span> を重みとして用いたい. より積極的に高評価があるものはよく反映するべきだし, また <span class="math inline">\(p=0\)</span> は必ずしも不評ではなく単に欠損値であるだけかもしれないから重みは小さくていい. <span class="math inline">\(r\)</span> が大きければ大きくなって, <span class="math inline">\(r=0\)</span> のときに <span class="math inline">\(1\)</span> であるような値として</p>
<ul>
<li><span class="math inline">\(c_{ui} = 1 + \alpha r_{ui}\)</span></li>
<li><span class="math inline">\(c_{ui} = 1 + \alpha \log (1 + r_{ui} / \epsilon )\)</span></li>
</ul>
<p>を提案している. 彼らの実験では１つ目を使っている.</p>
<p><span class="math display">\[\mathcal L = \sum_{u,i} c_{ui} \| p_{ui} - x_u^T y_i \|^2 + \lambda \left( \|x_u\|^2 + \|y_i\|^2 \right)\]</span></p>
<h3 id="最適化">最適化</h3>
<p>（直接上の損失関数の最小化を勾配法とかでやってもいいと思うけど）<span class="math inline">\(X,Y\)</span> の片方を止めて微分をして極値の条件を求めるとと次の２つの関係が出てくる.</p>
<ul>
<li><span class="math inline">\(x_i = (Y^T C^u Y + \lambda I_f)^{-1} Y^T C^u p^u\)</span></li>
<li><span class="math inline">\(y_u = (X^T C^i X + \lambda I_f)^{-1} X^T C^i p^i\)</span></li>
</ul>
<p>ただしここで <span class="math inline">\(C^u\)</span> は対角行列であって <span class="math inline">\(C^u_{ii} = c_{ui}\)</span> というもの. 同様に <span class="math inline">\(C^i\)</span> は対角行列であって <span class="math inline">\(C^i_{uu} = c_{ui}\)</span> であるもの. <span class="math inline">\(p^u\)</span> は <span class="math inline">\(n\)</span> 次元ベクトルで <span class="math inline">\(p^u_i = p_{ui}\)</span> であるもの. 同様に <span class="math inline">\(p^i\)</span> は <span class="math inline">\(m\)</span> 次元ベクトルで <span class="math inline">\(p^i_u = p_{ui}\)</span> であるもの.</p>
<p>この２つの関係式を使って, 一方を止めて他方を最適化, というのを交互に繰り返すことで最適化ができる.</p>
<h3 id="説明的推薦">説明的推薦</h3>
<p>先の関係式を用いると, アイテムどうしの類似度が出てきて, 「このアイテムを購入したからこれがお薦め」という説明が可能. ユーザー <span class="math inline">\(u\)</span> へのアイテム <span class="math inline">\(i\)</span> のスコアは <span class="math inline">\(y_i^T x_u\)</span> で計算できるが, <span class="math inline">\(x_u\)</span> は先の関係から <span class="math inline">\(C^u, p^u, Y\)</span> で表現できて <span class="math display">\[s^u_i = y_i^T (Y^T C^u Y + \lambda I_f)^{-1} Y^T C^u p^u\]</span> 一旦この真中の <span class="math inline">\((Y^T C^u Y + \lambda I_f)^{-1}\)</span> を <span class="math inline">\(W^u\)</span> と書くと <span class="math display">\[s^u_i = y_i^T W^u Y^T C^u p^u\]</span> <span class="math inline">\(p^u\)</span> で 1 が立っているところを <span class="math inline">\(j_1, j_2, \ldots\)</span> とする. それ以外はゼロなので <span class="math display">\[s^u_i = \sum_j c_{uj} (y_i^T W^u y_j)\]</span> になる. <span class="math inline">\(y_i^T W^u y_j\)</span> という値を <span class="math inline">\(i\)</span> と <span class="math inline">\(j\)</span> との類似度と見ることが出来て, 結局スコアは <span class="math inline">\(u\)</span> が過去視聴/購入したアイテムとの類似度との線形結合である, と解釈できる.</p>
<h2 id="感想">感想</h2>
<p>手法自体は既にある正則化付き行列分解に重みを付けただけだけど, 最適化の式とアイテムの類似度の算出が面白い. その類似度が本当に説明になっているのかは眉唾だが, 「良い推薦システムは説明的であるべき」という主張は同意できる.</p>
<p>ところで重みなしにしたかったら <span class="math inline">\(C^u=I, C^i=I\)</span> にすればいいだけで, 正則化なしにしたかったら <span class="math inline">\(\lambda = 0\)</span> にすればいいだけなのだが, その場合 <span class="math inline">\(W^u = Y^T Y\)</span> であり, <span class="math inline">\(i\)</span> と <span class="math inline">\(j\)</span> の類似度として <span class="math inline">\(s_{ij} = y_i^T Y^T Y y_j = (Yy_i)^T (Yy_j)\)</span> となる. これはどんな値なんだろう. <span class="math inline">\(Y y_j\)</span> は <span class="math inline">\((y_k^T y_j)_k\)</span> なるベクトルで, <span class="math inline">\(Yy_i = (y_k^T y_j)_k\)</span> との内積をとると <span class="math inline">\(s_{ij} = \sum_k (y_k^T y_i) (y_k^T y_j)\)</span>.</p>
<p>何も考察せずにアイテムどうしの類似度を出せと言われたらつい <span class="math inline">\(y_i^T y_j\)</span> を計算してしまう. この単純な内積による類似度を <span class="math inline">\(t_{ij}\)</span> ということにすると, <span class="math inline">\(s_{ij} = \sum_k t_{ik} t_{kj}\)</span> となる. <span class="math inline">\(k\)</span> を仲介にした類似度?</p>
<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>
</body>
</html>
