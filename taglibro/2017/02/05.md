% Sun Feb  5 14:42:55 JST 2017

## 日記

### Sat Feb 4

ずっと買い忘れていた（もうすぐ無くなってしまう）ニベアクリームをようやく買った.
169g の缶入りのが一番コスパが良いと思ってるのでそればっかりを買っている.
コンビニで、思い出したついでに買おうと思ったら600円もしたので驚いた.
そんなに高いつもりでいつも買ってなかったので.
慌てて最寄りの (名前もわからないような) ドラッグストアで買うと1缶500円をちょい超えるくらいだった.
今、家計簿を開いてみると、マツモトキヨシで買った時は税込みで498円、2缶で926円、とあった.

<blockquote class="twitter-tweet" data-lang="en"><p lang="ja" dir="ltr">5/24新刊『ｼｪﾙｽｸﾘﾌﾟﾄﾏｶﾞｼﾞﾝ VOL.38 』USP研究所(978-4-904807-34-7) 15冊入荷●特集は｢機械学習で石川啄木を蘇らせる｣です｡ <a href="https://t.co/uCAQgAEwp3">pic.twitter.com/uCAQgAEwp3</a></p>&mdash; 書泉ブックタワーコンピュータ書売り場 (@shosen_bt_pc) <a href="https://twitter.com/shosen_bt_pc/status/736071756805328896">May 27, 2016</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

シェルスクリプトマガジンで何故か機械学習のコラムが連載されていたことを知った.
9回連載の内の最終回が今月号であった.
神保町の三省堂に行けば、二ヶ月前のバックナンバーまで手に入るので、最後の三回だけ読めた.
きっとシェルスクリプトで頑張ってるんだろうと思ったら、バリバリでPythonでバリバリで scikit-learn だった.
テーマは、石川啄木の、上の句だけがあって下の句が欠けた、未完の俳句があるらしいから、
その下の句をどうにか作ろうというもの.

ググるとその内容らしきものが
[イントロダクション - SunPro会誌 2016](https://sunpro.io/c89/pub/hakatashi/introduction)
にあった.

形態素をマルコフ連鎖で生成するところまでは同じだったが、
石川啄木らしさをナイーブベイズではなく、なぜかSVMでやっていた.
`sckit_learn` の
[SVM](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
には二値分類以上に、確率も推定する機能があるらしい.
それはあんまり、私の知っているSVMではないのだが、どういうことだろう.

"svm probability" でググると、まあまあヒットする.
例えば [確率推定つきの SVM を libsvm.rb で試してみる - Relevant, Timely, and Accurate](http://d.hatena.ne.jp/hfu/20071130/1196395305).
どういう計算をしてるのかわからん.
境界面に近いほどゼロで、離れるほど (あるいは学習データ点集合に近いほど) 100% に近づく、みたいなことだろうか.
昔そういうことをして、指導教官に、SVMはそういうんじゃないからと言われた記憶がある.

Pythonのコーナーを見ても、何のコーナーを見ても、すっかり、
AI=DeepLearning in Python
の本ばかりが並ぶ中、ゲームAIの本が一冊だけ、一緒に平積みにされていた.
世間とはつまり、本屋さんの棚分類である.
彼らは今だにJavaとJavaScriptの区別がつかない.

"「読まなくてもいい本」の読書案内:知の最前線を5日間で探検する"
という本を読んだ.
作者は「経済小説」の作家らしかった.
本の内容は大変に面白かったので
[booklog](http://booklog.jp/users/hiratan/archives/1/4480816798)
の方に読書感想文を書いた.
最後のまとめ的な章に「人文系の学問には騙されないようにし、時間を無駄にしないようにしましょう（多少意訳）」とあって、小気味良かった.

### Sun Feb 5

この頃ずっとベーシック圏論を読んでる.
発売されたその日に買って読み始めているが、どうしても平日は少しずつしか読めない.
演習を無視しないで進めることにした.
かなり易しく書かれてるのもあるけど、最近、群とか位相をちゃんと復習したおかげでかなり読めるようになった.
分からない語が出てきても Wikipedia を読めば理解できる程度にはなった.

## DeepSVM

SVMについて復習していて (これは一週間以上前の話であって、上に書いたのとは関係ない)
名高い rbf カーネルは
$k(x,y) = \langle \phi(x), \phi(y) \rangle$
の形に ($k$ から $\phi$ に) 分解できないという事実があるのを思い出した.
それこそ深い MLP なら、近似的に、そのような $\phi$ を導けるのではないか.
少なくとも、データが与えられる空間において、近似できればいいのだから、
出来ないことはないはずだ.
一度どんな形が描けるか見てみたいと、シャワーを浴びながら思った.

もしそのような $\phi$ があれば、SVM とは結局、
入力 $x$ を $\phi(x)$ に写した後、
簡単な線形分類器に掛けるものに過ぎない.
$\phi$ を MLP で学習すると共に、その後ろに Dense 層を一つ付け加えれば、カーネルを備えた SVM を MLP で再現したことになる.

こういうものは DeepSVM と言われ、2013年ごろには既に発表があった.
まあ、そりゃそうか.
こんなのを誰も思いついてないはずがない.

MNIST で DeepSVM の性能を調べたが、適当な CNN よりずっと劣った.

そして肝心の $\phi$ の形だが、それはまだ調べていない.

## 映画

### カードキャプターさくら

を見た.
私はテレビ放映版も何も見たことがなく、正真正銘、これが初めて見たカードキャプターさくらだった.
恐らく、地上放送版の中の、ある一つのエピソード、それも物語全体にさして大きな副作用を与えないような、
差し当りのないエピソードを選んで劇場版としたのだろう.
私も知ってるあのOP曲ではないのが残念だった.

### 実写版、咲

2/3 (Fri.) に上映開始.
次の火曜日に休みを取っているので、見に行こうと思っている.

### 夜は短し歩けよ乙女

これは4/7 (Fri.) 上映開始.
見に行くつもり.
しかし声優に、適当な有名人を使うようなアニメに落ちてしまった.
浅沼さんのままにシて欲しかった.
