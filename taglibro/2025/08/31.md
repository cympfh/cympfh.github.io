% 月報 2025/07, 2025/08

## Fri 04 Jul 2025
### 16:28:08 *作ってみたいVRChatワールド*

- 違う星のぼくらリスペクト
    - 人によって違う世界とオブジェクトが見えてる
    - オブジェクトの座標は共有されてるけど違う物が見えてる
        - 人によってはビールが見えてるけど、別の人には花が見えてる
- NPハードゲームワールド
    - 巡回セールスマン問題を手動で解く
        - 難易度別にAIがあってスコアが相対的に比較出来る
        - 協力プレイ
    - 四色塗り分け
        - 協力して地図を4色に塗り分ける
- 意図的に高遅延になってる
    - 何したら面白くできるかは不明

### 18:20:22 *SlimBlade Pro を買ってから一ヶ月が経った*

改めてAmazonページを見ると白色は在庫切れになってるね.
黒色でもいいんだけど黒色はつやつや素材になってて指紋が気になりそう.
白色はマット加工がなされてていつ見ても綺麗.

トラックパッドみたいなのは結局ソフトウェア的にトラックボールをエミュレートするものであって,
なら最初からトラックボールが良いとずっと私は主張してる.

しかし親指トラックボールは中途半端だ.
小指一本で操作するよりは楽だけど, どんなに付け根が太くても親指一本に任せるのにはいつか無理が来る.
それから,
人によるだろうけどマウスに立ち向かう際の腕の角度はシチュエーションで変わる.
その時時で結局マウスを最適な角度に持ってくる作業が必要になってしまう.

大玉トラックボールはその点問題ない.
左を向きながらでも右を向きながらでも, 立ち上がって触るときでも,
どんな角度でもただ球体がそこに鎮座してるだけだ.
使うときは指を曲げて摘むようなことはしないで, 常に手をニュートラルな状態,
指を伸ばした状態から筋肉をすべて緩めたその状態で,
好きな場所に球体をそっと触れ, 手首と腕を動かすのでいい.
手首が疲れたなら腕を動かせばいい.
腕が動かしにくいならその時は指先を動かせばいい.
右手が疲れたなら左手を使えばいい.
でかい球体があるだけだから, どうやったっていい.

でかい動きと細かな動きの切り替えだけは練習が必要だ.
一応は本体にDPIの切り替えボタンがあるけど, こんなのは使う人いないだろう.
これに頼らないで済む感度設定を頑張れ.
通常は大雑把に大きく, 最後は指先の動きで細かく動かす.
これだけ.

## Thu 10 Jul 2025
### 18:49:33 *論文読む*

#### "Why is Normalization Neccesary for Linear Recommenders?"

{{https://www.alphaxiv.org/abs/2504.05805}}

線形オートエンコーダ (LAE) 系レコメンダは2つのバイアスがある.
人気アイテムが過剰評価される Popularity Bias と,
近すぎるアイテムが過剰評価される Neiborhood Bias.

DAN (Data-Adaptive Normalization) という正規化手法を提案する.

- $D_U$: 対角行列
    - $D_{uu}$: ユーザ $u$ がインタラクトしたアイテム数
- $D_I$: 対角行列
    - $D_{ii}$: アイテム $i$ をインタラクトしたユーザ数

$$\mathcal{L} = \| D_U^{\beta/2} (X - XB) \|_F^2 + \| D_I^{\alpha/2} B D_I^{(1- \alpha)/2} \|_F^2$$

ユーザーに関する正規化とアイテムに関する正規化を２つやってることになる.
$\alpha, \beta$ はハイパーパラメータ.

#### "FEASE: Shallow AutoEncoding Recommender with Cold Start Handling via Side Features"

{{https://www.alphaxiv.org/abs/2504.02288v1}}

コールドスタート問題に対応するように EASE を拡張した.

ユーザーに関するコールドスタート問題を解決する.

ユーザー対アイテムのインタラクション行列に,
ユーザーの属性行列 $U$, アイテムの属性行列 $T$ を結合して,

$$Z = \begin{bmatrix}{cc} X & \beta U \\ \alpha T & 0 \end{bmatrix}$$

としてこの $Z$ について EASE する.

アイテムに関するコールドスタート問題.

アイテム間の類似度行列 $R$ を別途用意する.
例えばアイテムのテキスト表層情報から tf-idf で類似度を計算するなど.
これが $B$ とある程度近くなるようにする.

$$\| X - XB \| + \lambda \| B \| + \gamma \mathrm{diag}(B) + \delta \| R - B \|$$


## Fri 11 Jul 2025
### 16:28:00 *論文読む*

"Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data"

{{https://www.alphaxiv.org/abs/1605.06955v4}}

- 仮定
    - 正例は事前確率 $\theta_P$ で与えられる
    - 負例は事前確率 $\theta_N$ で与えられる
    - ラベルなしのデータがある
        - この中は $\theta_P$ と $\theta_N$ でそれぞれ本来正例と負例に振り分けられる
- Goal
    - 分類器 $g \colon \mathcal{X} \to \{-1,+1\}$ を得る
    - 損失関数 $\ell$
        - $\ell(g(x), y) \geq 0$
        - $\ell(g(x), y) = 0 \iff g(x) = y$
        - 例えば $\ell(g(x), y) = \max(0, 1 - g(x) \cdot y)$ は SVM によるソフトマージン
    - 損失関数の差
        - $\tilde\ell{g(x)} = \ell(g(x), +1) - \ell(g(x), -1)$
- 既存手法
    - PN 学習
        - $R_{PN}(g) = \theta_P \mathbb{E}_P [\ell(g(X), +1)] + \theta_N \mathbb{E}_N [\ell(g(X), -1)]$
    - PU 学習
        - $R_{PU}(g) = \theta_P \mathbb{E}_P [\tilde\ell(g(x))] + \mathbb{E}_U [\ell(g(X), -1)]$
    - NU 学習
        - $R_{NU}(g) = \theta_N \mathbb{E}_N [-\tilde\ell(g(x))] + \mathbb{E}_U [\ell(g(X), +1)]$
- 提案手法
    - PU-NU
        - 結果としてあまりよくない方式なのがわかっている
        - $R_{PU-NU}(g) = (1 - \gamma) R_{PU}(g) + \gamma R_{NU}(g)$


## Thu 24 Jul 2025
### 18:49:45

[二ヶ月前](//cympfh.cc/taglibro/2025/06/30#2-Thu%2029%20May%202025) に買った SlimBlade Pro だが,
もう一つ欲しくなってる.
しかし白色は Amazon では在庫がない.
色が好きなんじゃなくてマット素材が良いんで, 何色でも良いので出してくれ.

親指トラックボールがアホらしくなってしまった.
あんなに喜んで使ってたのに.

## Tue 29 Jul 2025
### 15:23:16 **PURE**

LLM-based User Profile Management for Recommender.

{{https://www.alphaxiv.org/ja/overview/2502.14541v2}}

`Profile Update for REcommender (PURE)` を提案する.
データセットは Amazon data.
ユーザーの過去のレビュー文を使ってユーザーの特徴を抽出する.
これをレコメンダに役立てる.

#### 要約

データセットにはユーザーの購入履歴以外にレビュー文もある.
LLM にそれらを与えてユーザーの属性情報をテキストで吐かせる.
適宜, プロファイルは更新していく.
なにかの方法でアイテムの候補を与えて, LLM にランク付けさせる.
LLM には Llama-3.2-3B-Instruct を使った.

#### 手法

- データセット
    - ユーザのレビュー文
    - ユーザアイテムへのインタラクト: 購入したアイテムの列
- レビュー抽出 $\mathcal E$
    - 各ユーザーについて
        - 初回だけ動かす
        - LLM で次を抽出させる
            - $l^u$, ユーザーはどんなアイテムを好むか
            - $d^u$, ユーザーはどんなアイテムを嫌うか
            - $f^u$, ユーザーはどんな属性を持つか
        - $P^u = (l^u, d^u, f^u)$
            - これをユーザープロファイルとして持つ
- プロファイル更新 $\mathcal U$
    - 時間経過に伴ってユーザーの好みや属性を更新する
    - 前回までの $(l^u, d^u, f^u)$ に, 新しく購入したアイテムの履歴を追加して次の $(l,d,f)$ を得る
        - ここで要約もさせる
- 推薦
    - 最新のプロファイル $P^u$,
    - 最近購入したアイテム $I^u$,
    - 候補アイテム $C^u$
    - LLM に $C^u$ の中をランク付けさせる

## Fri 01 Aug 2025
### 16:26:45 *論文読む*

#### "Autoencoders that don’t overfit towards the Identity"

[[https://proceedings.neurips.cc/paper/2020/file/e33d974aae13e4d877477d51d8bafdc4-Paper.pdf]]

オートエンコーダは何も考えないと恒等写像 (単位行列) に収束してしまう.
過学習の結果といえる.
denoising AE や Dropout, L2 正則化でこれを防ぎたいと考えるのが普通だが,
これらは直接このことを防ぐための手法ではないので必ずしも効果的ではない.
この論文では emphasized denoising AE を提案する.
これは直接恒等写像への収束を防ぐことを目的とした手法である.

##### 直感的な方法

DLAE (Denoising Linear Autoencoder) という手法（不明）がすでにある.
これは $X = X B$ となるような行列 $B$ を学習するもの.
ここで対角成分が一番小さくなるものを選べば良い.

$$\min \| X - XB \| + \| \Lambda^{1/2} B \|_F^2$$

$$\text{where } \Lambda = \frac{p}{1-p} \mathrm{diagMat}(\mathrm{diag}(X^T X))$$

ここで $\Lambda$ は正則化の係数になる対角行列.
すなわち $B$ の対角成分だけ小さくすることを目的とする.

これを解くと

$$B = I - (X^T X + \Lambda)^{-1} \Lambda$$

ただしこれでも対角成分がゼロになるようなことを保証はできない.

##### 提案する EDLAE (Emphasized Denoising Linear Autoencoder)

$$\min \| X - XB \| + \| \Lambda^{1/2} B \|_F^2 + \| B - I \|_F^2$$

に $\mathrm{diag}(B) = 0$ を制約として加える.

> この制約があるなら L2 正則化は不要では？ と見える.
> でも, ラグランジュの未定乗数で解いてると思うなら, あってもいいか.

（案の定）ラグランジュの未定乗数で解くと

$$B = I - C \cdot \mathrm{dMat}(1 \ominus \mathrm{diag}(C))$$

$$\text{where } C = (X^T X + \Lambda)^{-1}$$

を得る.

> ほとんど EASE と同じに見える...
> 何が違う？
> というかこの論文はなんで EASE に触れないのか？

#### "It's Enough: Relaxing Diagonal Constraints in Linear Autoencoders for Recommendation"

[[https://www.alphaxiv.org/ja/overview/2305.12922v1]]

EASE みたいな Linear Autoencoder はL2正則化と対角成分の制約で成っている.
経験的には NNs と同じか超えることもある.
これを解明したい.
そしてロングテール問題の解決をどうしたらいいか考えたい.

##### Related Works

- LAE
    - $\min \|X-XB\|_F^2 + \lambda \|B\|_F^2$
- EASE
    - $\min \|X-XB\|_F^2 + \lambda \|B\|_F^2$ s.t. $\mathrm{diag}(B) = 0$
- DLAE
    - $\min \|X-XB\|_F^2 + \| \Lambda^{1/2} B\|_F^2$
- EDLAE
    - $\min \|X-XB\|_F^2 + \| \Lambda^{1/2} B\|_F^2$ s.t. $\mathrm{diag}(B) = 0$

##### 解析結果

- L2 正則化
    - 人気アイテムに偏らせる
- 対角成分の制約
    - 不人気アイテムを無視する

##### Relaxing

LAE または EASE から次を定義する.

- RLAE
    - $\min \|X-XB\|_F^2 + \lambda \|B\|_F^2$ s.t. $\mathrm{diag}(B) \leq \xi$
        - $\xi$ は定数ハイパラ
        - 特に $\xi = 0$ のときこれは EASE

これも閉形式解を持つ.

また同様に DAE と EDLAE から RDAE を定義できる.

##### 実験

Figure 3 は RLAE の $\xi$ を変化させたときの結果.
$\xi=0$ のときは EASE と同等.
$\xi$ を大きくするにつれて TAIL の精度があがり, HEAD は下がってそう.
トレードオフかな.


## Tue 05 Aug 2025
### 11:26:19 *最近見たアニメ*

- 忍者と殺し屋
    - ラストがあっさり
- 無職転生
    - 人に強く薦められて見た
    - 確かに良かった
- タコピー
    - 全6話であっさりしててよかった
    - オチはやや不服
- 瑠璃の宝石
    - 今一話だけ見た
    - 教養+セクシー


## Sun 10 Aug 2025
### 19:05:13 *エアフライヤーを買った*

`[山善] ノンフライヤー 4.5L` ってやつ.
今一番楽しいオモチャを手に入れた気分.
8/6 に家に届いてから毎日何かしら試してる.

- 冷凍食品のポテト
    - 冷凍食品は冷凍したままでいいんで入れてやればいい.
- 冷凍食品の唐揚げ
    - 思ったより簡単に焦げるので注意
- スーパーの惣菜コーナーの唐揚げ
    - 電子レンジでチンして美味しいようなものはエアフライヤで不味くなりようがない
- ウインナー
    - フライパンでものを
- ハンバーガー

買う前までは, 冷凍食品の揚げ物を本当に揚げ直したような出来を再現するための調理器具だと思ってた.
実際にはもっと万能だった.
揚げでもないし焼きでもないし電子レンジのような温めでもない.
それらのちょうど中間にある.

- 冷凍食品
    - ポテトとか唐揚げとか
    - 冷凍した状態のまま入れてOK
    - 思ったより簡単に焦げるので温度と時間は要調整
- お惣菜コーナーの唐揚げ
    - レンチンで温め直すくらいならエアフライヤーをとりあえず使っていい
    - 絶対美味しくなることが保証されてる
- フライパンでやるような料理
    - ウインナーをこれで焼くとか
    - 豚肉をこれで焼くとか
- ハンバーガー
    - レンチンで温め直す代わりにエアフライヤーでやってみる
    - パンがカリッとして美味しい

私の最近発明した簡単レシピを紹介する.
まず準備としてクッキングシートを底に敷いておく.
うまく行けば使い終わったあとエアフライヤーは汚れずクッキングシートを丸めて捨てるだけで済む.
豚バラ肉だけを敷いて180度5分焼く.
もうこれで食べてもお腹を壊さない程度の加熱はされてる.
豚バラ肉を裏返して, 大雑把にちぎったキャベツを上に乗せ, しめじなんかも上に乗せる.
そしてまた180度5分焼く.
お皿に盛り付けたらめんつゆを掛けて完成.
追加で大葉とかネギを添えると嬉しい.

ところでエアフライヤーには「ノンフライヤー」っていう名称もある.
ノンフライヤーは「揚げ物ではない」ことを言ってる.
エアフライヤーは「空気による揚げ物である」ことを言ってる.
実際には同じものだ.
私は「何をしないか」じゃなくて「何をするか」で語る大人になりたいので,
エアフライヤーと呼ぶことにする.

## Sat 16 Aug 2025
### 13:27:14 *思ってること*

- 文ちゃんが死んだときにどこに埋葬するべきか
- 家に大量に眠ってる昔のHHKB メルカリに全部出そう
    - HHKB Studio はゴミだった
    - Hybrid Type-S が決定版ということでいいと思う


## Mon 18 Aug 2025
### 18:46:24

- ツキノワグマ
    - 体長
        - 1.2-1.8m
    - 体毛
        - 黒い
    - 分布
        - 千葉県以外の本州
        - 四国は一部で絶滅危機
        - 九州は絶滅とされてる
- ヒグマ
    - 体長
        - 2.0-2.8m
    - 体毛
        - 茶色
    - 分布
        - 北海道
            - エゾヒグマによる三毛別羆事件
        - 本州では絶滅

## Thu 21 Aug 2025
### 14:32:25

NDCG の計算方法を誤って覚えてた.
今理解した.

$N$ 個のアイテムを並べるのに内部で各アイテム $i$ に確信度スコア $s_i$ を与える.
それとは別に真の適合度 $g_i$ も与える.
$s_i$ が高いほど $g_i$ が高いと嬉しい.
逆に $g_i$ が低いアイテムには $s_i$ を低くできてるほど嬉しい.

$s_i$ はアイテムの順序を決定するためだけに使う.
$s_i$ に関して降順（大きい順）に並び替えて $g_1, g_2, \ldots, g_N$ を取り出す.
そして

$$\mathrm{DCG}(g) = g_1 + \sum_{i=2}^N \frac{g_i}{\log_2(i)}$$

と計算する.
そして DCG の上限は $g_i$ に関して降順に並び替えて $g_1^\ast, g_2^\ast, \ldots, g_N^\ast$ を取り出して

$$\mathrm{DCG}^\ast(g) = g_1^\ast + \sum_{i=2}^N \frac{g_i^\ast}{\log_2(i)}$$

これを以て

$$\mathrm{NDCG}(g) = \frac{\mathrm{DCG}(g)}{\mathrm{DCG}^\ast(g)}$$

とする.
$s_i$ は並び替えにしか使ってないので,
順序を保存する関数 $f \colon \mathbb R \to \mathbb R$ があれば (つまり $x \leq y \iff f(x) \leq f(y)$ な関数), $f$ を $s$ に適用しても NDCG の値は変わらない.

$g$ と $s$ を別々に持つと思ってなかったのでずっと考え間違いをしてた (常に $g=s$ にするんだと思ってた).

```python
from sklearn.metrics import ndcg_score

g = [[4, 2, 3, 0, 1]]
s = [[1.0, 0.75, 0.5, 0.0, 0.25]]  # swap 2 and 3
print(ndcg_score(g, s))  # 0.982121886438581

s = [[x**2.0 for x in s[0]]]  # preserve the order
print(ndcg_score(g, s))  # 0.982121886438581
```

`s` はソートにしか使ってないので当然値は変わらない.

scikit-leran の実装でも `argsort` にしか `y_score` ($s$) は使われてない.

{{https://github.com/scikit-learn/scikit-learn/blob/c5497b7f7eacfaff061cf68e09bcd48aa93d4d6b/sklearn/metrics/_ranking.py#L1539}}


## Mon 25 Aug 2025
### 17:40:51

読むべき論文

"A Pre-trained Zero-shot Sequential Recommendation Framework via Popularity Dynamics"
https://arxiv.org/html/2401.01497v5
ドメイン (U,V) に依存しない推薦モデルを作る

"Personalized Playback Technology: How Short Video Services Create Excellent User Experience"
https://arxiv.org/html/2410.17073v2
ByteDance による TikTok (Douyin) の解説

