<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="unidoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>From RankNet to LambdaRank to LambdaMART: An Overview - Microsoft Research</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="https://cympfh.cc/resources/css/youtube.css" />
  <link href="https://unpkg.com/prismjs@1.x.0/themes/prism.css" rel="stylesheet" />
  <script id="MathJax-script" async src="https://unpkg.com/mathjax@3/es5/tex-chtml-full.js"></script>
  <link href="resources/css/c.css" rel="stylesheet" />
  <link href="../resources/css/c.css" rel="stylesheet" />
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />

</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o"></i></a>
</header>

<h1 class="title">From RankNet to LambdaRank to LambdaMART: An Overview - Microsoft Research</h1>
<p><ul> <li>original paper: <a href=https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/#>https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/#</a></li> </ul> <div class='is-pulled-right'> <a class='tag is-blue' href=index.html#順序学習>順序学習</a> </div></p>
<h2>概要</h2>
<p><a href="ranknet.html">RankNet</a> というのがあった. 大小比較に関する確率をスコアの差で表現するというやつだった. それをベースにした LambdaRank があり、さらにそれを決定木にしたのが <strong>LambdaMART</strong> というやつ. "2010 Yahoo! Learning To Rank Challenge" とかいうやつの 1 位.</p>
<h2>RankNet</h2>
<p>アイテム \(x_i, x_j\) に対してスコア \(s_i, s_j\) を算出する. この算出する過程を訓練可能なものにする. このスコアから確率</p>
\[P_{ij} = Pr\left[x_i \succ x_j\right] = \sigma(-k (s_i - s_j))\]
<p>を仮定して学習を行う. ここで \(\sigma\) はシグモイド関数. [^1] でもオリジナル論文 [^3] でも、シグモイド関数として \(\sigma\) を使ってないばかりか、 パラメータ (実数) として \(\sigma\) を使っている、のだが個人的に紛らわしいので、シグモイド関数は \(\sigma\) とするし、パラメータは \(k\) とする. オリジナル論文ではパラメータなんてものはそもそも無かったと思うけど.</p>
<p>教師信号として、 \(\bar{P}_{ij} \in \{ 0, 1&#x2F;2, 1\}\) を使う. \(x_i \succ x_j\) が与えられてたら \(\bar{P}_{ij} = 1\) . \(\bar{P}_{ij} = 1&#x2F;2 \iff i=j\) . こんな感じで.</p>
<p>損失関数は交差エントロピー.</p>
\[C = - \bar{P_{ij}} \log P_{ij} - (1 - \bar{P_{ij}}) \log (1 - P_{ij})\]
<p>\(C\) からスコアまでの勾配を求めると、</p>
\[\frac{\partial C}{\partial s_i}
= k \left( 1 - \bar{P}_{ij} - \sigma( - k (s_i - s_j) ) \right)
= - \frac{\partial C}{\partial s_j}\]
<p>\(x_i\) からスコアを算出する機械に関する勾配は、そのパラメータ \(w\) に就いて、</p>
\[\delta w
= \eta \frac{\partial C}{\partial w}
= \eta \left[
\frac{\partial C}{\partial s_i} \frac{\partial s_i}{\partial w}
+ \frac{\partial C}{\partial s_j} \frac{\partial s_j}{\partial w}
\right]\]
<p>これで \(w \leftarrow w - \delta w\) とかやって更新できる. ここで \(\eta\) は適当な学習係数.</p>
<h3>学習の高速化</h3>
<p>我々は \(C\) の値そのものではなく、その勾配に興味がある.</p>
<p>データセットを \(I = \{ (i,j) : x_i \succ x_j \}\) というペアの集合だとする. 予め \(\delta w\)</p>
<p>データセット \(I\) 中の全てのペアについて上の \(\delta w\) を求めて \(w\) を更新するのは、結局、 予め全てのペアについて</p>
\[\delta w = \eta \sum_{(i,j) \in I}
\left[
\lambda_{ij} \frac{\partial s_i}{\partial w} + \lambda_{ji} \frac{\partial s_j}{\partial w}
\right]\]
<p>という和を計算して使うのと同じ.</p>
<p>ここで、先程の \(\frac{\partial C}{\partial s_i}\) を \(\lambda_{ij}\) と書いている. さらに、</p>
\[\lambda_i = \sum_{j, (i,j) \in I} \lambda_{ij} - \sum_{j, (j,i) \in I} \lambda_{ij}\]
<p>とすると、</p>
\[\delta w = \eta \lambda_{i} \frac{\partial s_i}{\partial w}\]
<p>となる. この等号は分かりにくい.</p>
<h2>LambdaRank</h2>
<p>RankNet において</p>
\[\lambda_{ij}
= \frac{\partial C}{\partial s_i}
= k \left( 1 - \bar{P}_{ij} - \sigma( - k (s_i - s_j) ) \right)\]
<p>だったわけだが、これを簡略化して</p>
\[\lambda_{ij} = - k ~ \sigma( - k (s_i - s_j) ) |\Delta Z|\]
<p>としてしまったほうが経験的に良いらしい. ここで \(\Delta Z\) は NDCG (そういう名前のランキングの指標があるらしい [^4] ) の変化率. 他にも ERR なりなんなりでも良いらしい [^2] . 要するに最終的な評価指標の勾配 (の絶対値) を直接ここに入れてしまう.</p>
<p>これは \((i, j) \in I\) に対して</p>
\[C_{ij} = \log (1 + \exp( - (s_i - s_j) ) ) |\Delta Z|\]
<p>を損失関数にしたときのそれに相当するそう.</p>
<p>これが LambdaRank.</p>
<h2>LambdaMART</h2>
<p>LambdaMART は LambdaRank に MART という boosted tree model を組み合わせたものらしい.</p>
<h3>MART</h3>
<p>読む</p>
<h3>LambdaMART</h3>
<p>読む</p>
<h2>参考文献</h2>
<p>[^1] : <a href="https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/#">From RankNet to LambdaRank to LambdaMART: An Overview - Microsoft Research</a> [^2] : <a href="http://blog.csdn.net/huagong_adu/article/details/40710305">Learning To Rank之LambdaMART的前世今生 - Stay hungry, Stay foolish - CSDN博客</a> [^3] : <a href="http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf">RankNet のオリジナル論文</a> [^4] : <a href="http://szdr.hatenablog.com/entry/2017/02/24/235539">予測ランキング評価指標：NDCGの2つの定義と特徴の比較 - 人間だったら考えて</a></p>

<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>

  <script src="https://cympfh.cc/resources/js/youtube.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>