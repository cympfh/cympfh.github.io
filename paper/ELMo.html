<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Deep contextualized word reprensetations (Embedding from Language Models; ELMo)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../resources/css/c.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header class="page-header">
    <a href='index.html'><i class="fa fa-send-o" style="position:absolute; left:0.4em; top:0.4em; width:1.3em;border-radius:0.8em;"></i></a>
</header>
<header>
<h1 class="title">Deep contextualized word reprensetations (Embedding from Language Models; ELMo)</h1>
</header>
<ul>
<li>
original paper: <a href=http://www.aclweb.org/anthology/N18-1202>http://www.aclweb.org/anthology/N18-1202</a>
</li>
</ul>
<div class="is-pulled-right">
<p><a class='tag is-blue' href=index.html#深層学習>深層学習</a> <a class='tag is-blue' href=index.html#単語分散表現>単語分散表現</a></p>
</div>
<p><span class="math display">\[
\def\vec#1{\overrightarrow{#1}}
\def\cev#1{\overleftarrow{#1}}
\]</span></p>
<h2 id="概要">概要</h2>
<p>つよつよ単語分散表現を作る. タイトルにあるとおり &quot;deep contextualized&quot; であることを目指す. 他の単語分散表現と違って, 単語一個にベクトルを与えるのではなくて, 文全体を取ってから単語にベクトルを与えることをする. 関連として [Melamud et al,. 2016] の context2vec は pivot word とその周辺の context からベクトルを作るものがある.</p>
<p>[Chelba et al,. 2014] の 30 million sentences をデータセットに 2層 bi-LSTM で Language Model を作る.</p>
<h2 id="bidirectional-language-model-bilm">Bidirectional Language Model (biLM)</h2>
<p><span class="math inline">\(N\)</span> 個のトークンからなる文 <span class="math inline">\((t_1, \ldots, t_N)\)</span> について普通の forward な language model は <span class="math display">\[p(t_1,\ldots,t_N) = \prod_{k=1}^N p(t_k | t_1,\ldots,t_{k-1})\]</span> という右辺の <span class="math inline">\(p\)</span> を与えるもの.</p>
<p>これをLSTMなんかで学習するとセルは内部状態 <span class="math inline">\(h\)</span> を持つ. 全部で <span class="math inline">\(L\)</span> 層あるときに トークン <span class="math inline">\(t_k\)</span> を読んだ直後に <span class="math inline">\(j=1,\ldots,L\)</span> 層目の LSTM のセルが持つ状態を <span class="math inline">\(\vec{h_{k,j}}\)</span> とする. <span class="math inline">\(t_{k+1}\)</span> は <span class="math inline">\(\vec{h_{k,L}}\)</span> を使って予測されるわけである.</p>
<p>backward な language model とはトークン列の順序を逆順にしただけのもので <span class="math display">\[p(t_1,\ldots,t_N) = \prod_{k=1}^N p(t_k | t_{k+1},\ldots,t_N)\]</span> という右辺の <span class="math inline">\(p\)</span> を与えるもの. 同様に <span class="math inline">\(j\)</span> 層目の LSTM のセルが <span class="math inline">\(t_k\)</span> を読んだ直後に持つ状態を <span class="math inline">\(\cev{h_{k,j}}\)</span> とする.</p>
<p>bidirectional な language model は以上の forward と backward を次のように組み合わせる: <span class="math display">\[p(t_1,\ldots,t_N) = \prod_{k=1}^N p(t_k | t_1,\ldots,t_{k-1}) \times \prod_{k=1}^N p(t_k | t_{k+1},\ldots,t_N)\]</span> ここで 右辺の2つの <span class="math inline">\(p\)</span> をパラメータを持つわけだが、 token representation のためのパラメータ <span class="math inline">\(\Theta_x\)</span> と 最後の softmax layer のパラメータ <span class="math inline">\(\Theta_s\)</span> は共通して持たせる. つまり一層目と最終層だけ共通.</p>
<h2 id="elmo">ELMo</h2>
<p>ELMo は biLM の中の <span class="math inline">\(h\)</span> を使う. トークン <span class="math inline">\(t_k\)</span> を何かしらの方法でまずはベクトル化してるわけだがそれを <span class="math inline">\(x_k\)</span> とし、またそれを <span class="math inline">\(0\)</span> 層目の状態 <span class="math inline">\(h_{k,0}\)</span> と見做す. また forward の <span class="math inline">\(h\)</span> と backward の <span class="math inline">\(h\)</span> を結合して <span class="math inline">\(h_{k,j} = [ \vec{h_{k,j}}; \cev{h_{k,j}} ]\)</span> とする.</p>
<p>ELMo では <span class="math inline">\([t_1,\ldots,t_N]\)</span> における <span class="math inline">\(t_k\)</span> の表現を次の集合で表す: <span class="math display">\[R_k = \{ x_k, \vec{h_{k,j}}, \cev{h_{k,j}} ~|~ j=1,\ldots,L \} = \{ h_{k,j} ~|~ j=0,1,\ldots,L \}\]</span></p>
<!--

  以下を埋め込むと H2 タグを列挙してそれぞれへのリンクにする.
  ただし "INDEX" は除外する.

    <div id=toc></div>


  H2, H3 タグまでを列挙するには以下を埋め込む.

    <div id=toc-level-2></div>

-->
<script>
(function() {

  function naming(obj, name) {
      var PREF = document.createElement('a');
      PREF.name = name;
      obj.appendChild(PREF);
  }

  function level1() {

    var sections = document.getElementsByTagName('h2');
    var OL = document.createElement('ol');
    for (var i=0; i < sections.length; ++i) {
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = sections[i].innerHTML;
      if (A.innerHTML.toUpperCase() == 'INDEX') continue;
      A.href = '#' + i;
      LI.appendChild(A);
      OL.appendChild(LI);
      naming(sections[i], i);
      // var PREF = document.createElement('a');
      // PREF.name = i;
      // sections[i].appendChild(PREF);
    }

    return OL;
  }

  function level2() {

    var sections = document.querySelectorAll('h2,h3');
    var tree = [];
    for (var i = 0; i < sections.length; ++i) {
      if (sections[i].tagName == 'H2') {
        if (sections[i].innerHTML.toUpperCase() === 'INDEX') continue;
        tree.push([sections[i]]);
      } else {
        if (tree.length > 0) {
          tree[tree.length-1].push(sections[i]);
        } else {
          tree.push([sections[i]]);
        }
      }
    }

    var OL = document.createElement('ol');
    for (var i = 0; i < tree.length; ++i) {

      // h2-level
      var LI = document.createElement('li');
      var A = document.createElement('a');
      A.innerHTML = tree[i][0].innerHTML;
      A.href = '#' + i;
      naming(tree[i][0], i);
      LI.appendChild(A);

      // h3-level
      if (tree[i].length > 1) {
        var OL_sub = document.createElement('ol');
        for (var j = 1; j < tree[i].length; ++j) {
          var LI_sub = document.createElement('li');
          var A = document.createElement('a');
          A.innerHTML = tree[i][j].innerHTML;
          A.href = `#${i}-${j}`;
          naming(tree[i][j], `${i}-${j}`);
          LI_sub.appendChild(A);
          OL_sub.appendChild(LI_sub);
        }
        LI.appendChild(OL_sub);
      }

      OL.appendChild(LI);
    }

    return OL;
  }

  function append_toc() {
    if (document.getElementById('toc')) {
      document.getElementById('toc').appendChild(level1());
    }
    if (document.getElementById('toc-level-2')) {
      document.getElementById('toc-level-2').appendChild(level2());
    }
  }

  window.addEventListener('DOMContentLoaded', append_toc, false);
}());
</script>
</body>
</html>
